[{"path":"index.html","id":"comentarios","chapter":"1 Comentarios","heading":"1 Comentarios","text":"TFG de Ángel López-Mujeriego Collado del grado de la UOC: “Ciencia de Datos Aplicada”. En primer lugar haré un análsis introductorio de como la Ética interactúa con la IA. En segundo lugar describiré lo que es la aplicacion hecha con Shiny y con la librería “shinydashboard” ya que esta permite generar diversas pestañas las cuales cada una de ellas son una aplicación independiente.En los capítulos seguientes se genera un curso de inginiería de prompts para utilizar de forma eficiente ChatGPT.","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"introducción-a-la-ética-en-la-ia","chapter":"2 Introducción a la Ética en la IA","heading":"2 Introducción a la Ética en la IA","text":"La importancia de la ética en la IA:La inteligencia artificial (IA) está transformando diversas áreas de nuestra sociedad, incluyendo la salud, la industria, los seguros, los medios de comunicación y muchas más. medida que la IA asume un papel más prominente, surge una necesidad crítica de garantizar su uso ético y responsable. En su núcleo, la ética trata de determinar lo que está bien y lo que está mal, y guiar nuestras acciones basándonos en principios morales. Esto es especialmente relevante en el contexto de la IA, donde las decisiones automatizadas pueden tener un impacto significativo en las vidas humanas (Crawford, Cowling, & Allen, 2023).La ética de la IA ha ganado una atención significativa por parte del público en general, la industria y la academia. Con el bombo y el crecimiento alrededor de la IA, asegurar su uso apropiado y responsable solo es necesario, sino esencial. Sin directrices éticas claras, los sistemas de IA pueden desarrollar sesgos intencionados, perpetuar desigualdades existentes y tomar decisiones que sean científicamente razonables pero éticamente dudosas (Tawfeeq, Awqati, & Jasim, 2023).Ejemplos de aplicaciones de la IA:La IA tiene aplicaciones vastas y variadas en nuestra sociedad actual. continuación se presentan algunos ejemplos específicos de cómo se está utilizando la IA en diferentes sectores y los desafíos éticos que pueden surgir en cada caso:Salud: La IA y la robótica pueden mejorar la precisión en cirugías y diagnósticos, reduciendo el estrés cognitivo y físico de los pacientes. Por ejemplo, los algoritmos de IA combinados con programas de detección de cáncer han llevado una detección más temprana de enfermedades y mejores tasas de recuperación. Los sistemas de IA pueden analizar grandes volúmenes de datos médicos para identificar patrones y tendencias que los médicos humanos podrían pasar por alto. Sin embargo, si los datos de entrenamiento contienen sesgos, las decisiones de la IA pueden ser injustas o incorrectas (Rahimi & Abadi, 2023).Salud: La IA y la robótica pueden mejorar la precisión en cirugías y diagnósticos, reduciendo el estrés cognitivo y físico de los pacientes. Por ejemplo, los algoritmos de IA combinados con programas de detección de cáncer han llevado una detección más temprana de enfermedades y mejores tasas de recuperación. Los sistemas de IA pueden analizar grandes volúmenes de datos médicos para identificar patrones y tendencias que los médicos humanos podrían pasar por alto. Sin embargo, si los datos de entrenamiento contienen sesgos, las decisiones de la IA pueden ser injustas o incorrectas (Rahimi & Abadi, 2023).Seguros y Finanzas: La IA puede automatizar el procesamiento de reclamaciones, detectar fraudes y determinar primas de seguros. Sin embargo, sin una ética adecuada, estos sistemas pueden desarrollar sesgos, como denegar desproporcionadamente las reclamaciones de ciertos clientes debido los sesgos presentes en los datos de entrenamiento. Un modelo de IA que procesa reclamaciones de seguros y comienza denegar desproporcionadamente las reclamaciones de un cliente en particular puede perpetuar injusticias sociales y económicas. Es crucial que los datos utilizados para entrenar estos modelos sean diversos y representativos de todas las poblaciones (Tawfeeq, Awqati, & Jasim, 2023).Seguros y Finanzas: La IA puede automatizar el procesamiento de reclamaciones, detectar fraudes y determinar primas de seguros. Sin embargo, sin una ética adecuada, estos sistemas pueden desarrollar sesgos, como denegar desproporcionadamente las reclamaciones de ciertos clientes debido los sesgos presentes en los datos de entrenamiento. Un modelo de IA que procesa reclamaciones de seguros y comienza denegar desproporcionadamente las reclamaciones de un cliente en particular puede perpetuar injusticias sociales y económicas. Es crucial que los datos utilizados para entrenar estos modelos sean diversos y representativos de todas las poblaciones (Tawfeeq, Awqati, & Jasim, 2023).Medios de Comunicación y Publicidad: La IA se utiliza para personalizar la publicidad y el contenido en línea. Los algoritmos pueden analizar el comportamiento de los usuarios para mostrarles anuncios y contenido relevante. Sin embargo, esto puede llevar problemas de privacidad y manipulación. Los sistemas de IA pueden recopilar grandes cantidades de datos personales sin el conocimiento del usuario y utilizarlos de manera que los usuarios anticiparon ni consintieron. Además, la personalización excesiva puede llevar la creación de burbujas de información, donde los usuarios solo ven contenido que refuerza sus creencias y opiniones existentes (Rahimi & Abadi, 2023).Medios de Comunicación y Publicidad: La IA se utiliza para personalizar la publicidad y el contenido en línea. Los algoritmos pueden analizar el comportamiento de los usuarios para mostrarles anuncios y contenido relevante. Sin embargo, esto puede llevar problemas de privacidad y manipulación. Los sistemas de IA pueden recopilar grandes cantidades de datos personales sin el conocimiento del usuario y utilizarlos de manera que los usuarios anticiparon ni consintieron. Además, la personalización excesiva puede llevar la creación de burbujas de información, donde los usuarios solo ven contenido que refuerza sus creencias y opiniones existentes (Rahimi & Abadi, 2023).Justicia Penal: Algunos sistemas de IA se utilizan para prever el riesgo de reincidencia de los delincuentes y ayudar en las decisiones de libertad condicional. Sin embargo, estos sistemas pueden estar sesgados contra ciertos grupos raciales o socioeconómicos si los datos de entrenamiento reflejan prejuicios existentes en el sistema de justicia. Es crucial que estos sistemas sean transparentes y responsables, y que sus decisiones puedan ser auditadas y desafiadas (Crawford, Cowling, & Allen, 2023).Justicia Penal: Algunos sistemas de IA se utilizan para prever el riesgo de reincidencia de los delincuentes y ayudar en las decisiones de libertad condicional. Sin embargo, estos sistemas pueden estar sesgados contra ciertos grupos raciales o socioeconómicos si los datos de entrenamiento reflejan prejuicios existentes en el sistema de justicia. Es crucial que estos sistemas sean transparentes y responsables, y que sus decisiones puedan ser auditadas y desafiadas (Crawford, Cowling, & Allen, 2023).Para abordar los desafíos éticos mencionados anteriormente, es fundamental comprender y aplicar varios principios éticos en el desarrollo y uso de la IA. Estos principios ayudan garantizar que los sistemas de IA solo sean tecnológicamente avanzados, sino también moralmente responsables.Equidad:La equidad en la IA implica asegurar que los sistemas favorezcan un grupo sobre otro, especialmente en términos de raza, género o estatus socioeconómico. En la atención médica, por ejemplo, una IA que predice los resultados de los pacientes debe hacerlo de manera justa sin discriminar ningún grupo. Este principio es crucial para evitar la perpetuación de injusticias sociales y para asegurar que todos los individuos reciban un trato equitativo (Tawfeeq, Awqati, & Jasim, 2023).Para lograr la equidad, es importante que los datos utilizados para entrenar los modelos de IA sean representativos y libres de sesgos. Esto puede implicar la recopilación de datos de diversas fuentes y la implementación de técnicas de preprocesamiento de datos para eliminar cualquier sesgo inherente. Además, los modelos de IA deben ser evaluados continuamente para detectar y corregir cualquier sesgo que pueda surgir durante su uso (Rahimi & Abadi, 2023).Responsabilidad:La responsabilidad en la IA se refiere asignar la responsabilidad por los resultados e impactos de los sistemas de IA. Este principio es crucial para construir confianza en estos sistemas y asegurar que, cuando la IA cometa errores, haya un claro entendimiento de quién es responsable. Por ejemplo, si un sistema de IA en un hospital comete un error de diagnóstico, debe haber claridad sobre si la responsabilidad recae en el desarrollador del software, el médico que utiliza el sistema o el hospital que lo implementa (Crawford, Cowling, & Allen, 2023).La responsabilidad también implica la implementación de mecanismos para rendir cuentas y abordar los errores cuando ocurren. Esto puede incluir la creación de comités de revisión ética, la realización de auditorías regulares de los sistemas de IA y la provisión de vías claras para que los individuos presenten quejas y busquen reparación (Tawfeeq, Awqati, & Jasim, 2023).Transparencia:La transparencia es fundamental para entender y confiar en las decisiones de la IA. Involucra hacer que el proceso de toma de decisiones de la IA sea comprensible y accesible para todas las partes interesadas. Por ejemplo, las empresas deben ser claras sobre los datos utilizados para entrenar los modelos de IA y cómo se toman las decisiones basadas en estos datos. La transparencia ayuda asegurar que las decisiones de la IA puedan ser auditadas y verificadas, y que cualquier problema pueda ser identificado y corregido rápidamente (Rahimi & Abadi, 2023).Un aspecto clave de la transparencia es la explicabilidad, que se refiere la capacidad de entender cómo y por qué un sistema de IA toma una decisión específica. Esto puede implicar el uso de técnicas como LIME (Explicaciones de Modelos Locales e Interpretables) y SHAP (Explicaciones Aditivas de Shapley) para proporcionar explicaciones claras y comprensibles de las decisiones de la IA (Tawfeeq, Awqati, & Jasim, 2023).Paradoja de la privacidad y la personalización:La personalización de la IA puede comprometer la privacidad del usuario. Las empresas deben asegurar la alfabetización en IA para que los individuos comprendan cómo se rastrean y utilizan sus datos. Esta paradoja se refiere la tensión entre la personalización de los servicios y la protección de la privacidad del usuario. Por un lado, los usuarios desean servicios personalizados que se adapten sus preferencias y necesidades. Por otro lado, esta personalización menudo requiere la recopilación y análisis de grandes cantidades de datos personales, lo que puede comprometer la privacidad del usuario (Rahimi & Abadi, 2023).Para abordar esta paradoja, es crucial que las empresas implementen políticas de privacidad claras y transparentes. Los usuarios deben ser informados sobre qué datos se recopilan, cómo se utilizan y cómo se protegen. Además, las empresas deben proporcionar los usuarios opciones para controlar y gestionar sus datos personales, incluyendo la posibilidad de optar por participar en la recopilación de datos (Tawfeeq, Awqati, & Jasim, 2023).Dilema del sesgo y la equidad:Los datos de entrenamiento pueden llevar sesgos sociales que se reflejan en las decisiones de la IA, amplificando estos sesgos. Es crucial entrenar los modelos con datos justos y monitorear continuamente para detectar y corregir cualquier sesgo. Los sesgos pueden surgir de diversas fuentes, incluyendo la recopilación de datos, el diseño del modelo y las decisiones de implementación (Crawford, Cowling, & Allen, 2023).Para minimizar el sesgo, es importante realizar auditorías regulares de los sistemas de IA para identificar y corregir cualquier sesgo que pueda surgir. Además, las empresas deben implementar prácticas de recopilación de datos éticas que aseguren la diversidad y representatividad de los datos. Esto puede incluir la recopilación de datos de diversas fuentes, la inclusión de diferentes grupos demográficos y la implementación de técnicas de preprocesamiento de datos para eliminar cualquier sesgo inherente (Rahimi & Abadi, 2023).Complejidad y transparencia:Modelos de IA más complejos pueden proporcionar predicciones más precisas pero son difíciles de entender. La transparencia en estos casos requiere técnicas como LIME y SHAP para hacer comprensibles las decisiones de la IA. Estos métodos ayudan desentrañar la “caja negra” de los modelos de IA complejos y proporcionan explicaciones claras y comprensibles de las decisiones de la IA (Tawfeeq, Awqati, & Jasim, 2023).La complejidad de los modelos de IA también plantea desafíos para la auditoría y la verificación. Es crucial que las empresas implementen prácticas de documentación claras y detalladas que describan cómo se desarrollaron, entrenaron y probaron los modelos de IA. Esto puede incluir la documentación de los datos utilizados, los algoritmos implementados y los procesos de validación (Rahimi & Abadi, 2023).Autonomía y control:Los sistemas de IA autónomos pueden operar fuera del control humano, lo que plantea preguntas sobre hasta qué punto debemos permitir que operen sin supervisión humana. Este dilema se refiere la tensión entre la eficiencia y la seguridad. Por un lado, los sistemas de IA autónomos pueden aumentar la eficiencia al tomar decisiones rápidas y precisas sin intervención humana. Por otro lado, esta autonomía puede llevar decisiones que son deseables o seguras (Crawford, Cowling, & Allen, 2023).Para abordar este dilema, es crucial implementar mecanismos de supervisión humana y control. Esto puede incluir la implementación de sistemas de monitoreo en tiempo real, la provisión de mecanismos para la intervención humana en casos de emergencia y la definición clara de los límites y las condiciones bajo las cuales los sistemas de IA pueden operar de manera autónoma (Rahimi & Abadi, 2023).Ética por diseño:Integrar consideraciones éticas desde la etapa de diseño es crucial para asegurar que los sistemas de IA sean éticos y responsables desde el principio. La ética por diseño implica considerar las implicaciones éticas de cada decisión durante el desarrollo y la implementación del sistema de IA. Esto puede incluir la selección de datos de entrenamiento, el diseño de algoritmos, la implementación de sistemas y la evaluación de resultados (Tawfeeq, Awqati, & Jasim, 2023).Para implementar la ética por diseño, es importante seguir varios pasos clave:Definir objetivos claros: Esto implica establecer metas claras y específicas para el sistema de IA, incluyendo objetivos éticos. Por ejemplo, si el objetivo es desarrollar un sistema de IA para la atención médica, los objetivos éticos pueden incluir asegurar la equidad en el diagnóstico y tratamiento, proteger la privacidad del paciente y promover la transparencia en la toma de decisiones (Rahimi & Abadi, 2023).Definir objetivos claros: Esto implica establecer metas claras y específicas para el sistema de IA, incluyendo objetivos éticos. Por ejemplo, si el objetivo es desarrollar un sistema de IA para la atención médica, los objetivos éticos pueden incluir asegurar la equidad en el diagnóstico y tratamiento, proteger la privacidad del paciente y promover la transparencia en la toma de decisiones (Rahimi & Abadi, 2023).Involucrar las partes interesadas: Esto implica identificar y consultar todas las partes interesadas relevantes, incluyendo expertos en la industria, usuarios potenciales, defensores de la ética y reguladores. La participación de las partes interesadas ayuda identificar y abordar posibles preocupaciones éticas desde el principio (Crawford, Cowling, & Allen, 2023).Involucrar las partes interesadas: Esto implica identificar y consultar todas las partes interesadas relevantes, incluyendo expertos en la industria, usuarios potenciales, defensores de la ética y reguladores. La participación de las partes interesadas ayuda identificar y abordar posibles preocupaciones éticas desde el principio (Crawford, Cowling, & Allen, 2023).Recopilar y gestionar datos éticos: Esto implica asegurar que los datos utilizados para entrenar los modelos de IA sean diversos, representativos y libres de sesgos. También implica implementar prácticas de gestión de datos que protejan la privacidad y la seguridad de los datos personales (Tawfeeq, Awqati, & Jasim, 2023).Recopilar y gestionar datos éticos: Esto implica asegurar que los datos utilizados para entrenar los modelos de IA sean diversos, representativos y libres de sesgos. También implica implementar prácticas de gestión de datos que protejan la privacidad y la seguridad de los datos personales (Tawfeeq, Awqati, & Jasim, 2023).Diseñar sistemas transparentes: Esto implica implementar prácticas de diseño que promuevan la transparencia y la explicabilidad. Esto puede incluir la documentación clara y detallada de los procesos de desarrollo y entrenamiento, y la implementación de técnicas de explicabilidad como LIME y SHAP (Rahimi & Abadi, 2023).Diseñar sistemas transparentes: Esto implica implementar prácticas de diseño que promuevan la transparencia y la explicabilidad. Esto puede incluir la documentación clara y detallada de los procesos de desarrollo y entrenamiento, y la implementación de técnicas de explicabilidad como LIME y SHAP (Rahimi & Abadi, 2023).Evaluar el sesgo y la equidad: Esto implica realizar auditorías regulares de los sistemas de IA para identificar y corregir cualquier sesgo que pueda surgir. También implica implementar prácticas de monitoreo continuo para asegurar que los sistemas de IA sigan siendo justos y equitativos (Crawford, Cowling, & Allen, 2023).Evaluar el sesgo y la equidad: Esto implica realizar auditorías regulares de los sistemas de IA para identificar y corregir cualquier sesgo que pueda surgir. También implica implementar prácticas de monitoreo continuo para asegurar que los sistemas de IA sigan siendo justos y equitativos (Crawford, Cowling, & Allen, 2023).Implementar mecanismos para plantear preocupaciones: Esto implica proporcionar los usuarios y otras partes interesadas formas claras y accesibles para plantear preocupaciones sobre el impacto de la IA. Esto puede incluir la implementación de comités de revisión ética, la provisión de líneas directas para quejas y la realización de auditorías regulares de los sistemas de IA (Tawfeeq, Awqati, & Jasim, 2023).Implementar mecanismos para plantear preocupaciones: Esto implica proporcionar los usuarios y otras partes interesadas formas claras y accesibles para plantear preocupaciones sobre el impacto de la IA. Esto puede incluir la implementación de comités de revisión ética, la provisión de líneas directas para quejas y la realización de auditorías regulares de los sistemas de IA (Tawfeeq, Awqati, & Jasim, 2023).Iteración y evaluación continua: Esto implica evaluar y mejorar continuamente los sistemas de IA para asegurar que sigan siendo éticos y responsables. Esto puede incluir la implementación de procesos de mejora continua, la realización de auditorías regulares y la actualización de los sistemas de IA en respuesta nuevos desafíos y preocupaciones (Rahimi & Abadi, 2023).Iteración y evaluación continua: Esto implica evaluar y mejorar continuamente los sistemas de IA para asegurar que sigan siendo éticos y responsables. Esto puede incluir la implementación de procesos de mejora continua, la realización de auditorías regulares y la actualización de los sistemas de IA en respuesta nuevos desafíos y preocupaciones (Rahimi & Abadi, 2023).Ejemplos prácticos:MedTech: Para asegurar la equidad, MedTech prueba continuamente sus sistemas para detectar y rectificar sesgos. Define responsabilidades claras para cada resultado del sistema de IA y trabaja para que su sistema sea explicable y comprensible. Esto incluye la implementación de auditorías regulares para identificar y corregir sesgos, la provisión de documentación clara y detallada de los procesos de toma de decisiones y la implementación de técnicas de explicabilidad como LIME y SHAP (Tawfeeq, Awqati, & Jasim, 2023).MedTech: Para asegurar la equidad, MedTech prueba continuamente sus sistemas para detectar y rectificar sesgos. Define responsabilidades claras para cada resultado del sistema de IA y trabaja para que su sistema sea explicable y comprensible. Esto incluye la implementación de auditorías regulares para identificar y corregir sesgos, la provisión de documentación clara y detallada de los procesos de toma de decisiones y la implementación de técnicas de explicabilidad como LIME y SHAP (Tawfeeq, Awqati, & Jasim, 2023).Agrotech: Esta empresa ficticia utiliza un marco ético basado en sostenibilidad ambiental, viabilidad económica y equidad social para guiar el desarrollo de su serie de drones Smart Harvester, asegurando que sus innovaciones sean éticas y sostenibles. Esto incluye la identificación y consulta de todas las partes interesadas relevantes, la recopilación de datos diversos y representativos, y la implementación de prácticas de diseño transparentes y responsables (Rahimi & Abadi, 2023).Agrotech: Esta empresa ficticia utiliza un marco ético basado en sostenibilidad ambiental, viabilidad económica y equidad social para guiar el desarrollo de su serie de drones Smart Harvester, asegurando que sus innovaciones sean éticas y sostenibles. Esto incluye la identificación y consulta de todas las partes interesadas relevantes, la recopilación de datos diversos y representativos, y la implementación de prácticas de diseño transparentes y responsables (Rahimi & Abadi, 2023).La ética en el uso de modelos de lenguaje generativo, como ChatGPT, ha emergido como un tema crítico en la intersección de la inteligencia artificial (IA) y la sociedad. medida que estas tecnologías se integran más en la vida cotidiana y en contextos profesionales, es esencial evaluar las consideraciones éticas y las limitaciones inherentes su uso. Este documento explorará las implicaciones éticas del prompting en ChatGPT, utilizando los artículos proporcionados como bases para un análisis detallado (Hua et al., 2024; Pathak, 2024; Spennemann, 2023; Stahl & Eke, 2024).Definición y Uso del PromptingEl concepto de prompting se refiere la técnica utilizada para inducir un modelo de lenguaje como ChatGPT generar una respuesta específica. Esta técnica se basa en la formulación cuidadosa de entradas que pueden variar en complejidad, desde preguntas simples hasta escenarios detallados. La habilidad de manipular las respuestas de ChatGPT mediante prompting ha sido ampliamente explorada en diversas aplicaciones, incluyendo la creación de contenido, asistencia en la resolución de problemas y simulación de conversaciones humanas.Ejemplos de PromptingLos ejemplos de prompting pueden variar desde solicitar ChatGPT que redacte un ensayo sobre un tema específico hasta pedirle que genere código de programación. Estos prompts pueden ser simples o complejos, y su efectividad depende en gran medida de cómo se estructuran y del contexto proporcionado. Por ejemplo, un prompt bien diseñado puede guiar ChatGPT generar un ensayo coherente y bien estructurado, mientras que un prompt mal formulado puede resultar en una respuesta confusa o irrelevante.Manipulación y JailbreakingEl jailbreaking se refiere la práctica de diseñar prompts que obligan ChatGPT superar sus restricciones de seguridad y ética. Esta técnica es particularmente preocupante porque puede llevar que el modelo proporcione respuestas que violan los principios éticos y de seguridad para los cuales fue diseñado. El jailbreaking puede implicar la creación de escenarios complejos que engañan al modelo para que genere contenido inapropiado, lo que subraya la necesidad de fortalecer los mecanismos de seguridad y moderación.Estudios de Caso en JailbreakingEn el estudio de (Spennemann, 2023), se exploraron varios casos en los que se utilizaron prompts de jailbreaking para inducir ChatGPT proporcionar consejos sobre cómo hacer trampa en trabajos académicos. Estos estudios demostraron que, pesar de las salvaguardas implementadas, es posible manipular el modelo para generar respuestas que van en contra de las normas éticas establecidas. Estos hallazgos resaltan la necesidad de continuar mejorando los sistemas de seguridad y de educar los usuarios sobre los riesgos asociados con el uso inapropiado de la IA.Educación y Conocimiento del UsuarioLa educación de los usuarios es fundamental para asegurar un uso ético de ChatGPT. Los usuarios deben ser conscientes de las capacidades y limitaciones del modelo, así como de los posibles riesgos asociados con su uso. La falta de conocimiento puede llevar un uso indebido y la generación de contenido inapropiado o dañino. Por lo tanto, es esencial proporcionar formación y recursos que ayuden los usuarios entender cómo interactuar de manera responsable con la IA.Programas de Formación y Recursos EducativosLas instituciones educativas y organizaciones profesionales deben desarrollar programas de formación que aborden tanto los aspectos técnicos como éticos del uso de ChatGPT. Estos programas pueden incluir talleres, seminarios y cursos en línea que proporcionen una comprensión integral de cómo funciona el modelo, cómo diseñar prompts efectivos y éticos, y cómo evaluar críticamente las respuestas generadas por la IA. Además, se deben proporcionar recursos continuos y actualizados para mantener los usuarios informados sobre las últimas investigaciones y desarrollos en el campo de la ética de la IA.Respuestas Incoherentes y Falta de ResponsabilidadUna de las principales limitaciones de ChatGPT es su incapacidad para entender contextos complejos y sus implicaciones éticas. Esto puede llevar la generación de respuestas incoherentes o inapropiadas, especialmente en temas sensibles. La falta de discernimiento contextual puede resultar en la propagación de desinformación o en la difusión de ideas nocivas, lo que subraya la necesidad de un control humano riguroso y de pautas claras para el uso de la IA.Ejemplos de Respuestas IncoherentesEn situaciones donde se le pide ChatGPT que aborde temas éticamente complejos, como cuestiones de justicia social, políticas sensibles o dilemas morales, el modelo puede generar respuestas que carecen de la profundidad y sensibilidad necesarias para tratar adecuadamente estos temas. Por ejemplo, cuando se le pregunta sobre la ética de la manipulación genética, ChatGPT puede proporcionar información técnica precisa pero puede contextualizar completamente las implicaciones éticas y sociales de la práctica.Mecanismos de Seguridad y Moderación de ContenidoOpenAI ha implementado varios mecanismos de seguridad diseñados para moderar el contenido generado por ChatGPT. Estos mecanismos están destinados prevenir que el modelo genere respuestas que puedan ser perjudiciales, violentas o que inciten comportamientos ilegales o inmorales (Spennemann, 2023). Sin embargo, la efectividad de estos mecanismos es limitada y pueden ser superados mediante el uso de prompts sofisticados (Hua et al., 2024).Descripción de los Mecanismos de SeguridadLos mecanismos de seguridad incluyen filtros preentrenados que detectan contenido inapropiado y algoritmos de moderación que evalúan las respuestas generadas por el modelo. Estos sistemas están diseñados para identificar y bloquear contenido que viole las políticas de uso aceptable. obstante, los usuarios con suficiente conocimiento técnico pueden diseñar prompts que evadan estos filtros, lo que resalta la necesidad de una supervisión continua y mejoras en los sistemas de seguridad.Limitaciones Técnicas y Necesidad de Mejora ContinuaLas limitaciones técnicas de los modelos de lenguaje actuales, como ChatGPT, requieren mejoras continuas para robustecer sus capacidades de filtrado y moderación. Investigaciones futuras deben enfocarse en desarrollar algoritmos más sofisticados que puedan detectar y mitigar intentos de manipulación ética y proporcionar respuestas que estén alineadas con principios éticos establecidos (Stahl & Eke, 2024).Áreas Clave para la MejoraUna de las áreas clave para la mejora es el desarrollo de algoritmos que puedan entender mejor el contexto y las implicaciones éticas de las solicitudes de los usuarios. Esto podría incluir la implementación de modelos de IA que sean capaces de reconocer solo el contenido explícito de un prompt, sino también sus posibles implicaciones éticas y morales. Además, se debe investigar en la creación de sistemas que puedan aprender y adaptarse de manera dinámica nuevas formas de manipulación, mejorando así la capacidad de la IA para mantener respuestas éticas y seguras.Integración de Valores Éticos en el Diseño de IAPara avanzar hacia un uso más ético de los modelos de IA, es esencial integrar valores éticos desde las etapas iniciales del diseño y desarrollo. Esto implica solo la implementación de salvaguardas técnicas, sino también la promoción de una cultura de responsabilidad ética entre los desarrolladores y usuarios de IA (Hua et al., 2024).Principios de Diseño ÉticoLa integración de valores éticos puede lograrse mediante la adopción de principios de diseño centrados en el usuario y orientados la ética. Esto incluye la participación de expertos en ética en el proceso de desarrollo, así como la consulta con grupos de interés diversos para asegurar que se consideren múltiples perspectivas. Además, los desarrolladores deben comprometerse la transparencia en el diseño y operación de sus modelos de IA, proporcionando los usuarios información clara sobre cómo se gestionan y mitigan los riesgos éticos.Educación Continua y Conciencia del UsuarioLa educación continua sobre los riesgos y responsabilidades del uso de IA es crucial. Las instituciones educativas y organizaciones profesionales deben implementar programas de formación que aborden tanto las capacidades técnicas de ChatGPT como sus implicaciones éticas (Spennemann, 2023).Estrategias para la Educación ContinuaEstos programas de formación deben incluir módulos sobre la ética de la IA, estudios de casos sobre mal uso de la tecnología y estrategias para mitigar los riesgos. Además, se debe fomentar una cultura de aprendizaje continuo donde los usuarios se mantengan actualizados sobre las últimas investigaciones y desarrollos en la ética de la IA. Esto solo mejorará la comprensión de los usuarios sobre los riesgos y beneficios de la tecnología, sino que también promoverá un uso más informado y responsable.Políticas y RegulacionesFinalmente, la creación de políticas y regulaciones claras puede ayudar establecer estándares para el uso ético de la IA. Estas políticas deben ser desarrolladas en colaboración con expertos en ética, tecnólogos, y representantes de la sociedad civil para asegurar un enfoque holístico y equilibrado (Hua et al., 2024).Desarrollo de Políticas y RegulacionesLas políticas deben abordar aspectos clave como la transparencia, la responsabilidad y la rendición de cuentas en el uso de la IA. Esto incluye la exigencia de auditorías regulares de los sistemas de IA, la implementación de mecanismos de quejas y reparación para los usuarios afectados por decisiones de IA, y la promoción de estándares éticos internacionales que guíen el desarrollo y uso de la IA. Además, se debe fomentar la cooperación internacional para abordar los desafíos éticos de la IA, asegurando que las políticas sean consistentes y efectivas nivel global.La ética en la IA es un viaje continuo y dinámico. medida que la tecnología avanza, también lo hacen los desafíos y las soluciones éticas. Las organizaciones deben estar comprometidas con la ética desde el diseño de sus sistemas de IA hasta su implementación y monitoreo continuo. La ética de la IA solo es una buena práctica, sino también una ventaja competitiva que puede construir confianza y reputación en el mercado (Crawford et al., 2023).Es crucial que las organizaciones adopten un enfoque proactivo y holístico para la ética en la IA, asegurando que cada aspecto del desarrollo y uso de la IA sea considerado y abordado de manera ética. Esto incluye la implementación de principios éticos clave como la equidad, la responsabilidad y la transparencia, y la integración de consideraciones éticas en cada etapa del proceso de desarrollo (Mokdad Tawfeeq et al., 2023).Al adoptar prácticas éticas y responsables, las organizaciones pueden asegurar que la IA se utilice de manera que beneficie la sociedad y promueva el bienestar humano. Esto solo ayuda construir confianza y reputación, sino que también asegura que la IA siga siendo una herramienta valiosa y efectiva para resolver problemas complejos y mejorar nuestras vidas (Rahimi & Talebi Bezmin Abadi, 2023).En última instancia, la ética en la IA es fundamental para asegurar que los beneficios de la IA se realicen sin comprometer nuestros valores morales y éticos. medida que continuamos explorando y desarrollando nuevas tecnologías de IA, es esencial que mantengamos un enfoque constante en la ética y la responsabilidad, asegurando que la IA se utilice de manera que respete y promueva nuestros principios morales y valores éticos (Crawford et al., 2023) (Franklin, 2024).El uso de modelos de lenguaje generativo como ChatGPT presenta tanto oportunidades como desafíos significativos en términos de ética y responsabilidad. través de un análisis cuidadoso y la implementación de salvaguardas robustas, es posible maximizar los beneficios de estas tecnologías mientras se minimizan sus riesgos. La colaboración continua entre desarrolladores, usuarios y reguladores será esencial para navegar el complejo paisaje ético de la inteligencia artificial (Hua et al., 2024; Spennemann, 2023).Referencias:Crawford, J., Cowling, M., & Allen, K. (2023). Leadership needed ethical ChatGPT: Character, assessment, learning using artificial intelligence (AI). Journal University Teaching & Learning Practice, 20(3). https://doi.org/10.53761/1.20.3.02Crawford, J., Cowling, M., & Allen, K. (2023). Leadership needed ethical ChatGPT: Character, assessment, learning using artificial intelligence (AI). Journal University Teaching & Learning Practice, 20(3). https://doi.org/10.53761/1.20.3.02Franklin, J. (2024). AI Ethics - DataCamp Learn. https://app.datacamp.com/learn/courses/ai-ethicsFranklin, J. (2024). AI Ethics - DataCamp Learn. https://app.datacamp.com/learn/courses/ai-ethicsRahimi, F., & Abadi, . T. (2023). ChatGPT Publication Ethics. Archives Medical Research, 54(3), 272-274. https://doi.org/10.1016/j.arcmed.2023.03.004Rahimi, F., & Abadi, . T. (2023). ChatGPT Publication Ethics. Archives Medical Research, 54(3), 272-274. https://doi.org/10.1016/j.arcmed.2023.03.004Tawfeeq, M., Awqati, . J., & Jasim, Y. . (2023). Ethical Implications ChatGPT AI Chatbot: Review. Journal Modern Computing Engineering Research, 2023, 49-57.Tawfeeq, M., Awqati, . J., & Jasim, Y. . (2023). Ethical Implications ChatGPT AI Chatbot: Review. Journal Modern Computing Engineering Research, 2023, 49-57.Hua, S., Jin, S., & Jiang, S. (2024). Limitations Ethical Considerations ChatGPT. Data Intelligence, 6(1), 201–239. https://doi.org/10.1162/DINT_A_00243Hua, S., Jin, S., & Jiang, S. (2024). Limitations Ethical Considerations ChatGPT. Data Intelligence, 6(1), 201–239. https://doi.org/10.1162/DINT_A_00243Pathak, M. (2024). Ethical Considerations prompting ChatGPT Limitations | Mukul Pathak | Medium. https://mukulpatech.medium.com/ethical-considerations--prompting--chatgpt-limitations-9c32329d1694Pathak, M. (2024). Ethical Considerations prompting ChatGPT Limitations | Mukul Pathak | Medium. https://mukulpatech.medium.com/ethical-considerations--prompting--chatgpt-limitations-9c32329d1694Spennemann, D. H. R. (2023). Exploring Ethical Boundaries: Can ChatGPT Prompted Give Advice Cheat University Assignments? https://doi.org/10.20944/PREPRINTS202308.1271.V1Spennemann, D. H. R. (2023). Exploring Ethical Boundaries: Can ChatGPT Prompted Give Advice Cheat University Assignments? https://doi.org/10.20944/PREPRINTS202308.1271.V1Stahl, B. C., & Eke, D. (2024). ethics ChatGPT – Exploring ethical issues emerging technology. International Journal Information Management, 74, 102700. https://doi.org/10.1016/J.IJINFOMGT.2023.102700Stahl, B. C., & Eke, D. (2024). ethics ChatGPT – Exploring ethical issues emerging technology. International Journal Information Management, 74, 102700. https://doi.org/10.1016/J.IJINFOMGT.2023.102700","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"introducción","chapter":"2 Introducción a la Ética en la IA","heading":"2.1 Introducción","text":"La importancia de la ética en la IA:La inteligencia artificial (IA) está transformando diversas áreas de nuestra sociedad, incluyendo la salud, la industria, los seguros, los medios de comunicación y muchas más. medida que la IA asume un papel más prominente, surge una necesidad crítica de garantizar su uso ético y responsable. En su núcleo, la ética trata de determinar lo que está bien y lo que está mal, y guiar nuestras acciones basándonos en principios morales. Esto es especialmente relevante en el contexto de la IA, donde las decisiones automatizadas pueden tener un impacto significativo en las vidas humanas (Crawford, Cowling, & Allen, 2023).La ética de la IA ha ganado una atención significativa por parte del público en general, la industria y la academia. Con el bombo y el crecimiento alrededor de la IA, asegurar su uso apropiado y responsable solo es necesario, sino esencial. Sin directrices éticas claras, los sistemas de IA pueden desarrollar sesgos intencionados, perpetuar desigualdades existentes y tomar decisiones que sean científicamente razonables pero éticamente dudosas (Tawfeeq, Awqati, & Jasim, 2023).Ejemplos de aplicaciones de la IA:La IA tiene aplicaciones vastas y variadas en nuestra sociedad actual. continuación se presentan algunos ejemplos específicos de cómo se está utilizando la IA en diferentes sectores y los desafíos éticos que pueden surgir en cada caso:Salud: La IA y la robótica pueden mejorar la precisión en cirugías y diagnósticos, reduciendo el estrés cognitivo y físico de los pacientes. Por ejemplo, los algoritmos de IA combinados con programas de detección de cáncer han llevado una detección más temprana de enfermedades y mejores tasas de recuperación. Los sistemas de IA pueden analizar grandes volúmenes de datos médicos para identificar patrones y tendencias que los médicos humanos podrían pasar por alto. Sin embargo, si los datos de entrenamiento contienen sesgos, las decisiones de la IA pueden ser injustas o incorrectas (Rahimi & Abadi, 2023).Salud: La IA y la robótica pueden mejorar la precisión en cirugías y diagnósticos, reduciendo el estrés cognitivo y físico de los pacientes. Por ejemplo, los algoritmos de IA combinados con programas de detección de cáncer han llevado una detección más temprana de enfermedades y mejores tasas de recuperación. Los sistemas de IA pueden analizar grandes volúmenes de datos médicos para identificar patrones y tendencias que los médicos humanos podrían pasar por alto. Sin embargo, si los datos de entrenamiento contienen sesgos, las decisiones de la IA pueden ser injustas o incorrectas (Rahimi & Abadi, 2023).Seguros y Finanzas: La IA puede automatizar el procesamiento de reclamaciones, detectar fraudes y determinar primas de seguros. Sin embargo, sin una ética adecuada, estos sistemas pueden desarrollar sesgos, como denegar desproporcionadamente las reclamaciones de ciertos clientes debido los sesgos presentes en los datos de entrenamiento. Un modelo de IA que procesa reclamaciones de seguros y comienza denegar desproporcionadamente las reclamaciones de un cliente en particular puede perpetuar injusticias sociales y económicas. Es crucial que los datos utilizados para entrenar estos modelos sean diversos y representativos de todas las poblaciones (Tawfeeq, Awqati, & Jasim, 2023).Seguros y Finanzas: La IA puede automatizar el procesamiento de reclamaciones, detectar fraudes y determinar primas de seguros. Sin embargo, sin una ética adecuada, estos sistemas pueden desarrollar sesgos, como denegar desproporcionadamente las reclamaciones de ciertos clientes debido los sesgos presentes en los datos de entrenamiento. Un modelo de IA que procesa reclamaciones de seguros y comienza denegar desproporcionadamente las reclamaciones de un cliente en particular puede perpetuar injusticias sociales y económicas. Es crucial que los datos utilizados para entrenar estos modelos sean diversos y representativos de todas las poblaciones (Tawfeeq, Awqati, & Jasim, 2023).Medios de Comunicación y Publicidad: La IA se utiliza para personalizar la publicidad y el contenido en línea. Los algoritmos pueden analizar el comportamiento de los usuarios para mostrarles anuncios y contenido relevante. Sin embargo, esto puede llevar problemas de privacidad y manipulación. Los sistemas de IA pueden recopilar grandes cantidades de datos personales sin el conocimiento del usuario y utilizarlos de manera que los usuarios anticiparon ni consintieron. Además, la personalización excesiva puede llevar la creación de burbujas de información, donde los usuarios solo ven contenido que refuerza sus creencias y opiniones existentes (Rahimi & Abadi, 2023).Medios de Comunicación y Publicidad: La IA se utiliza para personalizar la publicidad y el contenido en línea. Los algoritmos pueden analizar el comportamiento de los usuarios para mostrarles anuncios y contenido relevante. Sin embargo, esto puede llevar problemas de privacidad y manipulación. Los sistemas de IA pueden recopilar grandes cantidades de datos personales sin el conocimiento del usuario y utilizarlos de manera que los usuarios anticiparon ni consintieron. Además, la personalización excesiva puede llevar la creación de burbujas de información, donde los usuarios solo ven contenido que refuerza sus creencias y opiniones existentes (Rahimi & Abadi, 2023).Justicia Penal: Algunos sistemas de IA se utilizan para prever el riesgo de reincidencia de los delincuentes y ayudar en las decisiones de libertad condicional. Sin embargo, estos sistemas pueden estar sesgados contra ciertos grupos raciales o socioeconómicos si los datos de entrenamiento reflejan prejuicios existentes en el sistema de justicia. Es crucial que estos sistemas sean transparentes y responsables, y que sus decisiones puedan ser auditadas y desafiadas (Crawford, Cowling, & Allen, 2023).Justicia Penal: Algunos sistemas de IA se utilizan para prever el riesgo de reincidencia de los delincuentes y ayudar en las decisiones de libertad condicional. Sin embargo, estos sistemas pueden estar sesgados contra ciertos grupos raciales o socioeconómicos si los datos de entrenamiento reflejan prejuicios existentes en el sistema de justicia. Es crucial que estos sistemas sean transparentes y responsables, y que sus decisiones puedan ser auditadas y desafiadas (Crawford, Cowling, & Allen, 2023).","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"principios-de-la-ética-en-la-ia","chapter":"2 Introducción a la Ética en la IA","heading":"2.2 Principios de la Ética en la IA","text":"Para abordar los desafíos éticos mencionados anteriormente, es fundamental comprender y aplicar varios principios éticos en el desarrollo y uso de la IA. Estos principios ayudan garantizar que los sistemas de IA solo sean tecnológicamente avanzados, sino también moralmente responsables.Equidad:La equidad en la IA implica asegurar que los sistemas favorezcan un grupo sobre otro, especialmente en términos de raza, género o estatus socioeconómico. En la atención médica, por ejemplo, una IA que predice los resultados de los pacientes debe hacerlo de manera justa sin discriminar ningún grupo. Este principio es crucial para evitar la perpetuación de injusticias sociales y para asegurar que todos los individuos reciban un trato equitativo (Tawfeeq, Awqati, & Jasim, 2023).Para lograr la equidad, es importante que los datos utilizados para entrenar los modelos de IA sean representativos y libres de sesgos. Esto puede implicar la recopilación de datos de diversas fuentes y la implementación de técnicas de preprocesamiento de datos para eliminar cualquier sesgo inherente. Además, los modelos de IA deben ser evaluados continuamente para detectar y corregir cualquier sesgo que pueda surgir durante su uso (Rahimi & Abadi, 2023).Responsabilidad:La responsabilidad en la IA se refiere asignar la responsabilidad por los resultados e impactos de los sistemas de IA. Este principio es crucial para construir confianza en estos sistemas y asegurar que, cuando la IA cometa errores, haya un claro entendimiento de quién es responsable. Por ejemplo, si un sistema de IA en un hospital comete un error de diagnóstico, debe haber claridad sobre si la responsabilidad recae en el desarrollador del software, el médico que utiliza el sistema o el hospital que lo implementa (Crawford, Cowling, & Allen, 2023).La responsabilidad también implica la implementación de mecanismos para rendir cuentas y abordar los errores cuando ocurren. Esto puede incluir la creación de comités de revisión ética, la realización de auditorías regulares de los sistemas de IA y la provisión de vías claras para que los individuos presenten quejas y busquen reparación (Tawfeeq, Awqati, & Jasim, 2023).Transparencia:La transparencia es fundamental para entender y confiar en las decisiones de la IA. Involucra hacer que el proceso de toma de decisiones de la IA sea comprensible y accesible para todas las partes interesadas. Por ejemplo, las empresas deben ser claras sobre los datos utilizados para entrenar los modelos de IA y cómo se toman las decisiones basadas en estos datos. La transparencia ayuda asegurar que las decisiones de la IA puedan ser auditadas y verificadas, y que cualquier problema pueda ser identificado y corregido rápidamente (Rahimi & Abadi, 2023).Un aspecto clave de la transparencia es la explicabilidad, que se refiere la capacidad de entender cómo y por qué un sistema de IA toma una decisión específica. Esto puede implicar el uso de técnicas como LIME (Explicaciones de Modelos Locales e Interpretables) y SHAP (Explicaciones Aditivas de Shapley) para proporcionar explicaciones claras y comprensibles de las decisiones de la IA (Tawfeeq, Awqati, & Jasim, 2023).","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"desafíos-éticos-en-la-ia","chapter":"2 Introducción a la Ética en la IA","heading":"2.3 Desafíos Éticos en la IA","text":"Paradoja de la privacidad y la personalización:La personalización de la IA puede comprometer la privacidad del usuario. Las empresas deben asegurar la alfabetización en IA para que los individuos comprendan cómo se rastrean y utilizan sus datos. Esta paradoja se refiere la tensión entre la personalización de los servicios y la protección de la privacidad del usuario. Por un lado, los usuarios desean servicios personalizados que se adapten sus preferencias y necesidades. Por otro lado, esta personalización menudo requiere la recopilación y análisis de grandes cantidades de datos personales, lo que puede comprometer la privacidad del usuario (Rahimi & Abadi, 2023).Para abordar esta paradoja, es crucial que las empresas implementen políticas de privacidad claras y transparentes. Los usuarios deben ser informados sobre qué datos se recopilan, cómo se utilizan y cómo se protegen. Además, las empresas deben proporcionar los usuarios opciones para controlar y gestionar sus datos personales, incluyendo la posibilidad de optar por participar en la recopilación de datos (Tawfeeq, Awqati, & Jasim, 2023).Dilema del sesgo y la equidad:Los datos de entrenamiento pueden llevar sesgos sociales que se reflejan en las decisiones de la IA, amplificando estos sesgos. Es crucial entrenar los modelos con datos justos y monitorear continuamente para detectar y corregir cualquier sesgo. Los sesgos pueden surgir de diversas fuentes, incluyendo la recopilación de datos, el diseño del modelo y las decisiones de implementación (Crawford, Cowling, & Allen, 2023).Para minimizar el sesgo, es importante realizar auditorías regulares de los sistemas de IA para identificar y corregir cualquier sesgo que pueda surgir. Además, las empresas deben implementar prácticas de recopilación de datos éticas que aseguren la diversidad y representatividad de los datos. Esto puede incluir la recopilación de datos de diversas fuentes, la inclusión de diferentes grupos demográficos y la implementación de técnicas de preprocesamiento de datos para eliminar cualquier sesgo inherente (Rahimi & Abadi, 2023).Complejidad y transparencia:Modelos de IA más complejos pueden proporcionar predicciones más precisas pero son difíciles de entender. La transparencia en estos casos requiere técnicas como LIME y SHAP para hacer comprensibles las decisiones de la IA. Estos métodos ayudan desentrañar la “caja negra” de los modelos de IA complejos y proporcionan explicaciones claras y comprensibles de las decisiones de la IA (Tawfeeq, Awqati, & Jasim, 2023).La complejidad de los modelos de IA también plantea desafíos para la auditoría y la verificación. Es crucial que las empresas implementen prácticas de documentación claras y detalladas que describan cómo se desarrollaron, entrenaron y probaron los modelos de IA. Esto puede incluir la documentación de los datos utilizados, los algoritmos implementados y los procesos de validación (Rahimi & Abadi, 2023).Autonomía y control:Los sistemas de IA autónomos pueden operar fuera del control humano, lo que plantea preguntas sobre hasta qué punto debemos permitir que operen sin supervisión humana. Este dilema se refiere la tensión entre la eficiencia y la seguridad. Por un lado, los sistemas de IA autónomos pueden aumentar la eficiencia al tomar decisiones rápidas y precisas sin intervención humana. Por otro lado, esta autonomía puede llevar decisiones que son deseables o seguras (Crawford, Cowling, & Allen, 2023).Para abordar este dilema, es crucial implementar mecanismos de supervisión humana y control. Esto puede incluir la implementación de sistemas de monitoreo en tiempo real, la provisión de mecanismos para la intervención humana en casos de emergencia y la definición clara de los límites y las condiciones bajo las cuales los sistemas de IA pueden operar de manera autónoma (Rahimi & Abadi, 2023).","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"implementación-de-la-ética-en-la-ia","chapter":"2 Introducción a la Ética en la IA","heading":"2.4 Implementación de la Ética en la IA","text":"Ética por diseño:Integrar consideraciones éticas desde la etapa de diseño es crucial para asegurar que los sistemas de IA sean éticos y responsables desde el principio. La ética por diseño implica considerar las implicaciones éticas de cada decisión durante el desarrollo y la implementación del sistema de IA. Esto puede incluir la selección de datos de entrenamiento, el diseño de algoritmos, la implementación de sistemas y la evaluación de resultados (Tawfeeq, Awqati, & Jasim, 2023).Para implementar la ética por diseño, es importante seguir varios pasos clave:Definir objetivos claros: Esto implica establecer metas claras y específicas para el sistema de IA, incluyendo objetivos éticos. Por ejemplo, si el objetivo es desarrollar un sistema de IA para la atención médica, los objetivos éticos pueden incluir asegurar la equidad en el diagnóstico y tratamiento, proteger la privacidad del paciente y promover la transparencia en la toma de decisiones (Rahimi & Abadi, 2023).Definir objetivos claros: Esto implica establecer metas claras y específicas para el sistema de IA, incluyendo objetivos éticos. Por ejemplo, si el objetivo es desarrollar un sistema de IA para la atención médica, los objetivos éticos pueden incluir asegurar la equidad en el diagnóstico y tratamiento, proteger la privacidad del paciente y promover la transparencia en la toma de decisiones (Rahimi & Abadi, 2023).Involucrar las partes interesadas: Esto implica identificar y consultar todas las partes interesadas relevantes, incluyendo expertos en la industria, usuarios potenciales, defensores de la ética y reguladores. La participación de las partes interesadas ayuda identificar y abordar posibles preocupaciones éticas desde el principio (Crawford, Cowling, & Allen, 2023).Involucrar las partes interesadas: Esto implica identificar y consultar todas las partes interesadas relevantes, incluyendo expertos en la industria, usuarios potenciales, defensores de la ética y reguladores. La participación de las partes interesadas ayuda identificar y abordar posibles preocupaciones éticas desde el principio (Crawford, Cowling, & Allen, 2023).Recopilar y gestionar datos éticos: Esto implica asegurar que los datos utilizados para entrenar los modelos de IA sean diversos, representativos y libres de sesgos. También implica implementar prácticas de gestión de datos que protejan la privacidad y la seguridad de los datos personales (Tawfeeq, Awqati, & Jasim, 2023).Recopilar y gestionar datos éticos: Esto implica asegurar que los datos utilizados para entrenar los modelos de IA sean diversos, representativos y libres de sesgos. También implica implementar prácticas de gestión de datos que protejan la privacidad y la seguridad de los datos personales (Tawfeeq, Awqati, & Jasim, 2023).Diseñar sistemas transparentes: Esto implica implementar prácticas de diseño que promuevan la transparencia y la explicabilidad. Esto puede incluir la documentación clara y detallada de los procesos de desarrollo y entrenamiento, y la implementación de técnicas de explicabilidad como LIME y SHAP (Rahimi & Abadi, 2023).Diseñar sistemas transparentes: Esto implica implementar prácticas de diseño que promuevan la transparencia y la explicabilidad. Esto puede incluir la documentación clara y detallada de los procesos de desarrollo y entrenamiento, y la implementación de técnicas de explicabilidad como LIME y SHAP (Rahimi & Abadi, 2023).Evaluar el sesgo y la equidad: Esto implica realizar auditorías regulares de los sistemas de IA para identificar y corregir cualquier sesgo que pueda surgir. También implica implementar prácticas de monitoreo continuo para asegurar que los sistemas de IA sigan siendo justos y equitativos (Crawford, Cowling, & Allen, 2023).Evaluar el sesgo y la equidad: Esto implica realizar auditorías regulares de los sistemas de IA para identificar y corregir cualquier sesgo que pueda surgir. También implica implementar prácticas de monitoreo continuo para asegurar que los sistemas de IA sigan siendo justos y equitativos (Crawford, Cowling, & Allen, 2023).Implementar mecanismos para plantear preocupaciones: Esto implica proporcionar los usuarios y otras partes interesadas formas claras y accesibles para plantear preocupaciones sobre el impacto de la IA. Esto puede incluir la implementación de comités de revisión ética, la provisión de líneas directas para quejas y la realización de auditorías regulares de los sistemas de IA (Tawfeeq, Awqati, & Jasim, 2023).Implementar mecanismos para plantear preocupaciones: Esto implica proporcionar los usuarios y otras partes interesadas formas claras y accesibles para plantear preocupaciones sobre el impacto de la IA. Esto puede incluir la implementación de comités de revisión ética, la provisión de líneas directas para quejas y la realización de auditorías regulares de los sistemas de IA (Tawfeeq, Awqati, & Jasim, 2023).Iteración y evaluación continua: Esto implica evaluar y mejorar continuamente los sistemas de IA para asegurar que sigan siendo éticos y responsables. Esto puede incluir la implementación de procesos de mejora continua, la realización de auditorías regulares y la actualización de los sistemas de IA en respuesta nuevos desafíos y preocupaciones (Rahimi & Abadi, 2023).Iteración y evaluación continua: Esto implica evaluar y mejorar continuamente los sistemas de IA para asegurar que sigan siendo éticos y responsables. Esto puede incluir la implementación de procesos de mejora continua, la realización de auditorías regulares y la actualización de los sistemas de IA en respuesta nuevos desafíos y preocupaciones (Rahimi & Abadi, 2023).Ejemplos prácticos:MedTech: Para asegurar la equidad, MedTech prueba continuamente sus sistemas para detectar y rectificar sesgos. Define responsabilidades claras para cada resultado del sistema de IA y trabaja para que su sistema sea explicable y comprensible. Esto incluye la implementación de auditorías regulares para identificar y corregir sesgos, la provisión de documentación clara y detallada de los procesos de toma de decisiones y la implementación de técnicas de explicabilidad como LIME y SHAP (Tawfeeq, Awqati, & Jasim, 2023).MedTech: Para asegurar la equidad, MedTech prueba continuamente sus sistemas para detectar y rectificar sesgos. Define responsabilidades claras para cada resultado del sistema de IA y trabaja para que su sistema sea explicable y comprensible. Esto incluye la implementación de auditorías regulares para identificar y corregir sesgos, la provisión de documentación clara y detallada de los procesos de toma de decisiones y la implementación de técnicas de explicabilidad como LIME y SHAP (Tawfeeq, Awqati, & Jasim, 2023).Agrotech: Esta empresa ficticia utiliza un marco ético basado en sostenibilidad ambiental, viabilidad económica y equidad social para guiar el desarrollo de su serie de drones Smart Harvester, asegurando que sus innovaciones sean éticas y sostenibles. Esto incluye la identificación y consulta de todas las partes interesadas relevantes, la recopilación de datos diversos y representativos, y la implementación de prácticas de diseño transparentes y responsables (Rahimi & Abadi, 2023).Agrotech: Esta empresa ficticia utiliza un marco ético basado en sostenibilidad ambiental, viabilidad económica y equidad social para guiar el desarrollo de su serie de drones Smart Harvester, asegurando que sus innovaciones sean éticas y sostenibles. Esto incluye la identificación y consulta de todas las partes interesadas relevantes, la recopilación de datos diversos y representativos, y la implementación de prácticas de diseño transparentes y responsables (Rahimi & Abadi, 2023).","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"el-prompting-y-sus-implicaciones-éticas","chapter":"2 Introducción a la Ética en la IA","heading":"2.5 El prompting y sus implicaciones éticas","text":"La ética en el uso de modelos de lenguaje generativo, como ChatGPT, ha emergido como un tema crítico en la intersección de la inteligencia artificial (IA) y la sociedad. medida que estas tecnologías se integran más en la vida cotidiana y en contextos profesionales, es esencial evaluar las consideraciones éticas y las limitaciones inherentes su uso. Este documento explorará las implicaciones éticas del prompting en ChatGPT, utilizando los artículos proporcionados como bases para un análisis detallado (Hua et al., 2024; Pathak, 2024; Spennemann, 2023; Stahl & Eke, 2024).","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"el-prompting-y-sus-implicaciones-éticas-1","chapter":"2 Introducción a la Ética en la IA","heading":"2.5.1 El Prompting y sus Implicaciones Éticas","text":"Definición y Uso del PromptingEl concepto de prompting se refiere la técnica utilizada para inducir un modelo de lenguaje como ChatGPT generar una respuesta específica. Esta técnica se basa en la formulación cuidadosa de entradas que pueden variar en complejidad, desde preguntas simples hasta escenarios detallados. La habilidad de manipular las respuestas de ChatGPT mediante prompting ha sido ampliamente explorada en diversas aplicaciones, incluyendo la creación de contenido, asistencia en la resolución de problemas y simulación de conversaciones humanas.Ejemplos de PromptingLos ejemplos de prompting pueden variar desde solicitar ChatGPT que redacte un ensayo sobre un tema específico hasta pedirle que genere código de programación. Estos prompts pueden ser simples o complejos, y su efectividad depende en gran medida de cómo se estructuran y del contexto proporcionado. Por ejemplo, un prompt bien diseñado puede guiar ChatGPT generar un ensayo coherente y bien estructurado, mientras que un prompt mal formulado puede resultar en una respuesta confusa o irrelevante.Manipulación y JailbreakingEl jailbreaking se refiere la práctica de diseñar prompts que obligan ChatGPT superar sus restricciones de seguridad y ética. Esta técnica es particularmente preocupante porque puede llevar que el modelo proporcione respuestas que violan los principios éticos y de seguridad para los cuales fue diseñado. El jailbreaking puede implicar la creación de escenarios complejos que engañan al modelo para que genere contenido inapropiado, lo que subraya la necesidad de fortalecer los mecanismos de seguridad y moderación.Estudios de Caso en JailbreakingEn el estudio de (Spennemann, 2023), se exploraron varios casos en los que se utilizaron prompts de jailbreaking para inducir ChatGPT proporcionar consejos sobre cómo hacer trampa en trabajos académicos. Estos estudios demostraron que, pesar de las salvaguardas implementadas, es posible manipular el modelo para generar respuestas que van en contra de las normas éticas establecidas. Estos hallazgos resaltan la necesidad de continuar mejorando los sistemas de seguridad y de educar los usuarios sobre los riesgos asociados con el uso inapropiado de la IA.","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"responsabilidad-y-uso-ético","chapter":"2 Introducción a la Ética en la IA","heading":"2.5.2 Responsabilidad y Uso Ético","text":"Educación y Conocimiento del UsuarioLa educación de los usuarios es fundamental para asegurar un uso ético de ChatGPT. Los usuarios deben ser conscientes de las capacidades y limitaciones del modelo, así como de los posibles riesgos asociados con su uso. La falta de conocimiento puede llevar un uso indebido y la generación de contenido inapropiado o dañino. Por lo tanto, es esencial proporcionar formación y recursos que ayuden los usuarios entender cómo interactuar de manera responsable con la IA.Programas de Formación y Recursos EducativosLas instituciones educativas y organizaciones profesionales deben desarrollar programas de formación que aborden tanto los aspectos técnicos como éticos del uso de ChatGPT. Estos programas pueden incluir talleres, seminarios y cursos en línea que proporcionen una comprensión integral de cómo funciona el modelo, cómo diseñar prompts efectivos y éticos, y cómo evaluar críticamente las respuestas generadas por la IA. Además, se deben proporcionar recursos continuos y actualizados para mantener los usuarios informados sobre las últimas investigaciones y desarrollos en el campo de la ética de la IA.Respuestas Incoherentes y Falta de ResponsabilidadUna de las principales limitaciones de ChatGPT es su incapacidad para entender contextos complejos y sus implicaciones éticas. Esto puede llevar la generación de respuestas incoherentes o inapropiadas, especialmente en temas sensibles. La falta de discernimiento contextual puede resultar en la propagación de desinformación o en la difusión de ideas nocivas, lo que subraya la necesidad de un control humano riguroso y de pautas claras para el uso de la IA.Ejemplos de Respuestas IncoherentesEn situaciones donde se le pide ChatGPT que aborde temas éticamente complejos, como cuestiones de justicia social, políticas sensibles o dilemas morales, el modelo puede generar respuestas que carecen de la profundidad y sensibilidad necesarias para tratar adecuadamente estos temas. Por ejemplo, cuando se le pregunta sobre la ética de la manipulación genética, ChatGPT puede proporcionar información técnica precisa pero puede contextualizar completamente las implicaciones éticas y sociales de la práctica.","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"la-ética-de-la-respuesta-de-la-ia","chapter":"2 Introducción a la Ética en la IA","heading":"2.5.3 La Ética de la Respuesta de la IA","text":"Mecanismos de Seguridad y Moderación de ContenidoOpenAI ha implementado varios mecanismos de seguridad diseñados para moderar el contenido generado por ChatGPT. Estos mecanismos están destinados prevenir que el modelo genere respuestas que puedan ser perjudiciales, violentas o que inciten comportamientos ilegales o inmorales (Spennemann, 2023). Sin embargo, la efectividad de estos mecanismos es limitada y pueden ser superados mediante el uso de prompts sofisticados (Hua et al., 2024).Descripción de los Mecanismos de SeguridadLos mecanismos de seguridad incluyen filtros preentrenados que detectan contenido inapropiado y algoritmos de moderación que evalúan las respuestas generadas por el modelo. Estos sistemas están diseñados para identificar y bloquear contenido que viole las políticas de uso aceptable. obstante, los usuarios con suficiente conocimiento técnico pueden diseñar prompts que evadan estos filtros, lo que resalta la necesidad de una supervisión continua y mejoras en los sistemas de seguridad.Limitaciones Técnicas y Necesidad de Mejora ContinuaLas limitaciones técnicas de los modelos de lenguaje actuales, como ChatGPT, requieren mejoras continuas para robustecer sus capacidades de filtrado y moderación. Investigaciones futuras deben enfocarse en desarrollar algoritmos más sofisticados que puedan detectar y mitigar intentos de manipulación ética y proporcionar respuestas que estén alineadas con principios éticos establecidos (Stahl & Eke, 2024).Áreas Clave para la MejoraUna de las áreas clave para la mejora es el desarrollo de algoritmos que puedan entender mejor el contexto y las implicaciones éticas de las solicitudes de los usuarios. Esto podría incluir la implementación de modelos de IA que sean capaces de reconocer solo el contenido explícito de un prompt, sino también sus posibles implicaciones éticas y morales. Además, se debe investigar en la creación de sistemas que puedan aprender y adaptarse de manera dinámica nuevas formas de manipulación, mejorando así la capacidad de la IA para mantener respuestas éticas y seguras.","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"consideraciones-futuras-y-recomendaciones","chapter":"2 Introducción a la Ética en la IA","heading":"2.5.4 Consideraciones Futuras y Recomendaciones","text":"Integración de Valores Éticos en el Diseño de IAPara avanzar hacia un uso más ético de los modelos de IA, es esencial integrar valores éticos desde las etapas iniciales del diseño y desarrollo. Esto implica solo la implementación de salvaguardas técnicas, sino también la promoción de una cultura de responsabilidad ética entre los desarrolladores y usuarios de IA (Hua et al., 2024).Principios de Diseño ÉticoLa integración de valores éticos puede lograrse mediante la adopción de principios de diseño centrados en el usuario y orientados la ética. Esto incluye la participación de expertos en ética en el proceso de desarrollo, así como la consulta con grupos de interés diversos para asegurar que se consideren múltiples perspectivas. Además, los desarrolladores deben comprometerse la transparencia en el diseño y operación de sus modelos de IA, proporcionando los usuarios información clara sobre cómo se gestionan y mitigan los riesgos éticos.Educación Continua y Conciencia del UsuarioLa educación continua sobre los riesgos y responsabilidades del uso de IA es crucial. Las instituciones educativas y organizaciones profesionales deben implementar programas de formación que aborden tanto las capacidades técnicas de ChatGPT como sus implicaciones éticas (Spennemann, 2023).Estrategias para la Educación ContinuaEstos programas de formación deben incluir módulos sobre la ética de la IA, estudios de casos sobre mal uso de la tecnología y estrategias para mitigar los riesgos. Además, se debe fomentar una cultura de aprendizaje continuo donde los usuarios se mantengan actualizados sobre las últimas investigaciones y desarrollos en la ética de la IA. Esto solo mejorará la comprensión de los usuarios sobre los riesgos y beneficios de la tecnología, sino que también promoverá un uso más informado y responsable.Políticas y RegulacionesFinalmente, la creación de políticas y regulaciones claras puede ayudar establecer estándares para el uso ético de la IA. Estas políticas deben ser desarrolladas en colaboración con expertos en ética, tecnólogos, y representantes de la sociedad civil para asegurar un enfoque holístico y equilibrado (Hua et al., 2024).Desarrollo de Políticas y RegulacionesLas políticas deben abordar aspectos clave como la transparencia, la responsabilidad y la rendición de cuentas en el uso de la IA. Esto incluye la exigencia de auditorías regulares de los sistemas de IA, la implementación de mecanismos de quejas y reparación para los usuarios afectados por decisiones de IA, y la promoción de estándares éticos internacionales que guíen el desarrollo y uso de la IA. Además, se debe fomentar la cooperación internacional para abordar los desafíos éticos de la IA, asegurando que las políticas sean consistentes y efectivas nivel global.","code":""},{"path":"introducción-a-la-ética-en-la-ia.html","id":"conclusión","chapter":"2 Introducción a la Ética en la IA","heading":"2.6 Conclusión","text":"La ética en la IA es un viaje continuo y dinámico. medida que la tecnología avanza, también lo hacen los desafíos y las soluciones éticas. Las organizaciones deben estar comprometidas con la ética desde el diseño de sus sistemas de IA hasta su implementación y monitoreo continuo. La ética de la IA solo es una buena práctica, sino también una ventaja competitiva que puede construir confianza y reputación en el mercado (Crawford et al., 2023).Es crucial que las organizaciones adopten un enfoque proactivo y holístico para la ética en la IA, asegurando que cada aspecto del desarrollo y uso de la IA sea considerado y abordado de manera ética. Esto incluye la implementación de principios éticos clave como la equidad, la responsabilidad y la transparencia, y la integración de consideraciones éticas en cada etapa del proceso de desarrollo (Mokdad Tawfeeq et al., 2023).Al adoptar prácticas éticas y responsables, las organizaciones pueden asegurar que la IA se utilice de manera que beneficie la sociedad y promueva el bienestar humano. Esto solo ayuda construir confianza y reputación, sino que también asegura que la IA siga siendo una herramienta valiosa y efectiva para resolver problemas complejos y mejorar nuestras vidas (Rahimi & Talebi Bezmin Abadi, 2023).En última instancia, la ética en la IA es fundamental para asegurar que los beneficios de la IA se realicen sin comprometer nuestros valores morales y éticos. medida que continuamos explorando y desarrollando nuevas tecnologías de IA, es esencial que mantengamos un enfoque constante en la ética y la responsabilidad, asegurando que la IA se utilice de manera que respete y promueva nuestros principios morales y valores éticos (Crawford et al., 2023) (Franklin, 2024).El uso de modelos de lenguaje generativo como ChatGPT presenta tanto oportunidades como desafíos significativos en términos de ética y responsabilidad. través de un análisis cuidadoso y la implementación de salvaguardas robustas, es posible maximizar los beneficios de estas tecnologías mientras se minimizan sus riesgos. La colaboración continua entre desarrolladores, usuarios y reguladores será esencial para navegar el complejo paisaje ético de la inteligencia artificial (Hua et al., 2024; Spennemann, 2023).Referencias:Crawford, J., Cowling, M., & Allen, K. (2023). Leadership needed ethical ChatGPT: Character, assessment, learning using artificial intelligence (AI). Journal University Teaching & Learning Practice, 20(3). https://doi.org/10.53761/1.20.3.02Crawford, J., Cowling, M., & Allen, K. (2023). Leadership needed ethical ChatGPT: Character, assessment, learning using artificial intelligence (AI). Journal University Teaching & Learning Practice, 20(3). https://doi.org/10.53761/1.20.3.02Franklin, J. (2024). AI Ethics - DataCamp Learn. https://app.datacamp.com/learn/courses/ai-ethicsFranklin, J. (2024). AI Ethics - DataCamp Learn. https://app.datacamp.com/learn/courses/ai-ethicsRahimi, F., & Abadi, . T. (2023). ChatGPT Publication Ethics. Archives Medical Research, 54(3), 272-274. https://doi.org/10.1016/j.arcmed.2023.03.004Rahimi, F., & Abadi, . T. (2023). ChatGPT Publication Ethics. Archives Medical Research, 54(3), 272-274. https://doi.org/10.1016/j.arcmed.2023.03.004Tawfeeq, M., Awqati, . J., & Jasim, Y. . (2023). Ethical Implications ChatGPT AI Chatbot: Review. Journal Modern Computing Engineering Research, 2023, 49-57.Tawfeeq, M., Awqati, . J., & Jasim, Y. . (2023). Ethical Implications ChatGPT AI Chatbot: Review. Journal Modern Computing Engineering Research, 2023, 49-57.Hua, S., Jin, S., & Jiang, S. (2024). Limitations Ethical Considerations ChatGPT. Data Intelligence, 6(1), 201–239. https://doi.org/10.1162/DINT_A_00243Hua, S., Jin, S., & Jiang, S. (2024). Limitations Ethical Considerations ChatGPT. Data Intelligence, 6(1), 201–239. https://doi.org/10.1162/DINT_A_00243Pathak, M. (2024). Ethical Considerations prompting ChatGPT Limitations | Mukul Pathak | Medium. https://mukulpatech.medium.com/ethical-considerations--prompting--chatgpt-limitations-9c32329d1694Pathak, M. (2024). Ethical Considerations prompting ChatGPT Limitations | Mukul Pathak | Medium. https://mukulpatech.medium.com/ethical-considerations--prompting--chatgpt-limitations-9c32329d1694Spennemann, D. H. R. (2023). Exploring Ethical Boundaries: Can ChatGPT Prompted Give Advice Cheat University Assignments? https://doi.org/10.20944/PREPRINTS202308.1271.V1Spennemann, D. H. R. (2023). Exploring Ethical Boundaries: Can ChatGPT Prompted Give Advice Cheat University Assignments? https://doi.org/10.20944/PREPRINTS202308.1271.V1Stahl, B. C., & Eke, D. (2024). ethics ChatGPT – Exploring ethical issues emerging technology. International Journal Information Management, 74, 102700. https://doi.org/10.1016/J.IJINFOMGT.2023.102700Stahl, B. C., & Eke, D. (2024). ethics ChatGPT – Exploring ethical issues emerging technology. International Journal Information Management, 74, 102700. https://doi.org/10.1016/J.IJINFOMGT.2023.102700","code":""},{"path":"introducción-a-la-aplicación.html","id":"introducción-a-la-aplicación","chapter":"3 Introducción a la aplicación","heading":"3 Introducción a la aplicación","text":"","code":""},{"path":"introducción-a-la-aplicación.html","id":"explicación-de-la-aplicación","chapter":"3 Introducción a la aplicación","heading":"3.1 Explicación de la aplicación","text":"La aplicación se ha realizado con Shiny, específicamente con la flexibilidad que proporciona la librería “shinydashboard” ya que esta permite generar diversas pestañas las cuales cada una de ellas son una aplicación independiente. La aplicación se encuentra disponible en el siguiente enlace:https://testestestest.shinyapps.io/TFGUOC/Cuando se hace clic en el enlace aparece la imagen siguiente 3.1:\nFigura 3.1: Aplicación de Shiny para interactuar con ChatGPT.\nLas 5 aplicaciones creadas se pueden ver en la parte superior izquierda tal y como se muestra en la 3.2.\nFigura 3.2: Cinco aplicaciones independientes creadas.\nTal y como se puede ver en la 3.2, las aplicaciones son las siguientes:UsuarioUsuario/(Sistema o Asistente)Crea una imagenTranscribe un audioTraduce un audio al inglés","code":""},{"path":"introducción-a-la-aplicación.html","id":"aplicación-usuario","chapter":"3 Introducción a la aplicación","heading":"3.2 Aplicación Usuario","text":"Tal y como muestra la 3.3, esta aplicación permite interactuar con ChatGPT de la que explicaré.\nFigura 3.3: Primera aplicación llamada Usuario.\nPrimero hace falta introducir la API key (3.4) con lo que se debe tener esta llave generada. En el siguiente enlace:https://platform.openai.com/account/api-keysse puede acceder generarla, guardarla y una vez se ha utilizado en una sesión es recomendable generar una nueva y borrar la anterior (3.5).\nFigura 3.4: Introducción de la API Key en la aplicación.\n\nFigura 3.5: Generación de la API Key en la web oficial de OpenAI.\nEl siguiente paso es escoger el tipo de modelo entrenado por OpenAI y tenemos 3 posibilidades en este caso, el más reciente, gpt-4o, seguido de gpt-4-turbo y gpt-3.5-turbo tal y como se puede ver en la 3.6.\nFigura 3.6: Modelos disponibles de OpenAI en la aplicación.\nEn la 3.7 se muestran los valores disponibles para la variable Temperatura, siendo 0 un valor faltado de aleatoriedad y más predecible y siendo 1 o más valores que generan texto con mayor variedad y creatividad. Dependiendo de lo que se necesite se va escoger el valor que se crea oportuno.\nFigura 3.7: Valores de la temperatura disponible para el modelo.\nEn la 3.8 se muestra donde se puedes escoger la longitud del texto generado variando desde 1 token 1000 tokens.\nFigura 3.8: Número de tokens escogido como longitud de la respuesta de 1 1000.\nEn la 3.9 se encuentra la parte en la que se encuentra el chat con la posibilidad de introducir el texto pregunta, con el botón enviar y el botón borrar historial cuando se desee.\nFigura 3.9: Historial del Chat, introducción del texto, botón de enviar y botón de borrar historial.\nEn la 3.10 se muestra un ejemplo sencillo en el que se pregunta “¿Cuál es la capital de Cataluña?” y la aplicación responde en el área verde “Claro, la capital de Cataluña es Barcelona. Es una ciudad conocida por su arquitecura, cultura y vibrante vida urbana”. Y debajo aparece de nuevo el pompt del usuario para poder seguir interactuando.\nFigura 3.10: Ejemplo de uso del chat de la aplicación.\n","code":""},{"path":"introducción-a-la-aplicación.html","id":"aplicación-usuariosistema-o-asistente","chapter":"3 Introducción a la aplicación","heading":"3.3 Aplicación Usuario/(Sistema o Asistente)","text":"En la 3.11 se muestra la segunda aplicación llamada Usuario/(Sistema o Asistente) y que es igual que la anterior con la diferencia de que hay un espacio llamado “SISTEMA DE PROMPT” donde el usuario tiene la opción de utilizar dos roles, el de usuario y el de sitema. Ya veremos más adelante como se puede utilizar de forma eficiente.\nFigura 3.11: Aplicación Usuario/(Sistema o Asistente) en la que se añade el sistema de prompt.\nEn la 3.12 se puede ver como en el sistema de prompt se ha especificado que realice respuestas solo si son de deporte y que de lo contrario indique que solo contesta este tipo de preguntas. En cambio, cuando se le pregunta ¿Qué es el fútbol? Responde claramente.\nFigura 3.12: Aplicación Usuario/(Sistema o Asistente) en la que se añade el sistema de prompt.\n","code":""},{"path":"introducción-a-la-aplicación.html","id":"aplicación-crea-una-imagen","chapter":"3 Introducción a la aplicación","heading":"3.4 Aplicación Crea una imagen","text":"La siguiente aplicación se llama “Crea una imagen” (3.13) y partir de la introducción de una propuesta en el área correspondiente y despues de clicar en el boton “Genera Imagen” la imagen se genera. Esta aplicación solo se puede ejecutar si previamente se han usado la primera o la segunda, ya que estas útlimas guardan la API Key en el sistema y ya hace falta introducirla de nuevo.\nFigura 3.13: Aplicación Crea una imagen.\nSe observa en la 3.14 como se ha generado una puesta de sol tal y como se había pedido. También se observa que las imágenes siempre son fotografías ya existentes, es decir, está utilizando Dall-E 3, sino que reutiliza imágenes de algún repositorio disponible.\nFigura 3.14: Uso de la Aplicación Crea una imagen para generar una puesta de sol.\n","code":""},{"path":"introducción-a-la-aplicación.html","id":"video-explicativo-de-como-utilizar-la-aplicación","chapter":"3 Introducción a la aplicación","heading":"3.5 Video explicativo de como utilizar la aplicación","text":"Explicación de como utilizar la aplicación:","code":""},{"path":"introducción-1.html","id":"introducción-1","chapter":"4 Introducción","heading":"4 Introducción","text":"La ingeniería de prompts se refiere la creación de instrucciones o prompts dados grandes modelos de lenguaje o LLMs, como CHTGPT, para obtener respuestas deseadas. Podemos pensar en la ingeniería de prompts como la elaboración de una receta para una comida deliciosa. Así como un chef experto selecciona y combina cuidadosamente los ingredientes para crear un plato delicioso, la ingeniería de prompts implica diseñar cuidadosamente los prompts que guían efectivamente al modelo hacia la producción de la salida deseada.La ingeniería de prompts es esencial para producir buenas salidas porque la calidad de las respuestas que obtenemos depende en gran medida de los prompts proporcionados, donde los prompts de alta calidad llevan respuestas de alta calidad y los prompts de baja calidad llevan respuestas de baja calidad. En este curso, dominaremos los principios de la ingeniería de prompts y las mejores prácticas para construir sistemas de IA que aprovechen las capacidades de los modelos de lenguaje. Ver la Figura 4.1.\nFigura 4.1: Descripción gráfica del buen funcionamiento de Chat GPT. (Hecho con Python).\n","code":""},{"path":"introducción-1.html","id":"uso-de-la-api-de-openai","chapter":"4 Introducción","heading":"4.1 Uso de la API de OpenAI","text":"Profundizaremos en varios tipos de prompts y algunas aplicaciones comerciales y aplicaremos estas habilidades utilizando la aplicación de Shiny que creado y de la cual dejo el link:https://testestestest.shinyapps.io/TFGUOC/La API de OpenAI permite la interacción con los modelos de OpenAI. Para usar la API, debemos obtener la clave iniciando sesión, visitando la página de claves API, creando una nueva clave secreta y copiándola para uso futuro. Si extraviamos nuestra clave, debemos eliminarla y generar una nueva.La API proporciona varios puntos de acceso, pero el principal utilizado para chatear es la finalización del chat. Este punto de acceso es perfecto para tareas de turno único y diálogos interactivos, lo que lo hace ideal para aplicaciones conversacionales como asistentes virtuales y chatbots. Cada mensaje de la API tiene uno de los tres roles: usuario, asistente o sistema. Los mensajes del sistema proporcionan instrucciones para guiar el comportamiento del modelo durante una conversación. Los mensajes de usuario son prompts del usuario. Y los mensajes de asistente son las respuestas los prompts del usuario.En el caso de mi aplicación si se quiere solo el rol de usuario se deberá utilizar la aplicación Prompt tal y como se muestra en la Figura 4.2.\nFigura 4.2: Aplicación Usuario utilizada solo como rol de usuario.\nSi se quieren usar los 3 roles (usuario, asistente o sistema) pasaremos utilizar la segunda aplicación llamada Usuario/(Sistema o asistente) ya que la entrada llamada SISTEMA DE PROMPT servirá tanto como Asistente o Sistema y la otra entrada es la del PROMPT DEL USUARIO tal y como se ve en la Figura 4.3.\nFigura 4.3: Aplicación Usuario/(Sistema o Asistente) utilizada si requerimos de los tres roles.\nRecordemos que la API tiene parámetros de control útiles. Uno de ellos es la temperatura, un valor entre cero y dos que controla la aleatoriedad de la respuesta. Dos hace que la respuesta sea muy aleatoria y 0 la hace determinista. Otro parámetro es Max tokens, que controla la longitud deseada de la respuesta.Supongamos que queremos preguntar “¿Qué es la ingeniería de prompts?” través de la primera aplicación “Usuario” (Figura 4.4). Para los parámetros de control, configuramos la temperatura en 0 para obtener respuestas deterministas, y especificamos Max tokens 101. Observamos en la Figura 4 que la pregunta propuesta primero devuelve una descripción, pero la última frase queda incompleta. Para evitar esto debemos mejorar el prompt y le decimos que lo defina en una sola frase y así lo hace. Por último, le hacemos la misma pregunta pero le especificamos que lo debe entender un niño de 5 años y que lo describa en dos frases.\nFigura 4.4: Aplicación Usuario para preguntar ¿Qué es la ingeniería de prompts?.\n","code":""},{"path":"introducción-1.html","id":"nuestra-primera-interacción-con-chatgpt","chapter":"4 Introducción","heading":"4.2 Nuestra primera interacción con ChatGPT","text":"Supongamos que queremos preguntar “¿Qué es la ingeniería de prompts?” través de la primera aplicación “Usuario” (Figura 4.4). Para los parámetros de control, configuramos la temperatura en 0 para obtener respuestas deterministas, y especificamos Max tokens 101. Observamos en la Figura 4 que la pregunta propuesta primero devuelve una descripción, pero la última frase queda incompleta. Para evitar esto debemos mejorar el prompt y le decimos que lo defina en una sola frase y así lo hace. Por último, le hacemos la misma pregunta pero le especificamos que lo debe entender un niño de 5 años y que lo describa en dos frases.","code":""},{"path":"principios-de-la-ingeniería-de-prompts.html","id":"principios-de-la-ingeniería-de-prompts","chapter":"5 Principios de la Ingeniería de Prompts","heading":"5 Principios de la Ingeniería de Prompts","text":"Ahora profundizaremos en los principios clave de la ingeniería de prompts para crear prompts más efectivos. Al interactuar con un LLM, apuntamos prompts claros y precisos para lograr los mejores resultados. Podemos pensar en este proceso como guiar alguien de un lugar otro, donde buscamos seleccionar el camino más simple y efectivo entre varias opciones disponibles. Exploraremos 4 principios de la ingeniería de prompts, incluyendo el uso de verbos de acción apropiados, instrucciones, descripciones precisas y prompts delimitados bien estructurados.Al pedirle al modelo que realice ciertas tareas, opta por verbos de acción que guíen explícitamente la tarea del modelo, como escribir, completar, explicar, describir o evaluar. Por el contrario, evita usar verbos ambiguos como entender, pensar, sentir, intentar y saber, que podrían confundir la comprensión del modelo. Un prompt que le pida al modelo que piense sobre el problema de la deforestación es ineficaz. Aunque el modelo genere alguna salida sobre la deforestación, el prompt requiere una mayor claridad respecto las expectativas. Para mejorar el prompt, usamos un verbo de acción que explícitamente le diga al modelo qué hacer. Por ejemplo, le pedimos al modelo que proponga estrategias para reducir la deforestación y, en consecuencia, el modelo ofrece algunas soluciones. En la Figura 5.1 se observa claramente como mejora la respuesta utilizando verbos apropiados.\nFigura 5.1: Mejorando las respuestas utilizando verbos apropiados.\nAl elaborar prompts, querremos proporcionar instrucciones específicas, descriptivas y detalladas sobre el contexto, la longitud de la salida, el formato, el estilo y la audiencia. Por ejemplo, consideramos un prompt que pide al modelo de lenguaje que nos hable sobre los perros como ineficaz porque es demasiado amplio. Sin embargo, decirle al modelo que describa el comportamiento y las características de una raza de perro específica, como los golden retrievers, permite al modelo ser más preciso con su respuesta (Figura 5.2).\nFigura 5.2: Mejorando las respuestas utilizando descripciones más precisas.\nAl elaborar prompts, trata de evitar descripciones imprecisas. Por ejemplo, pedir al modelo que genere un texto corto sobre la ingeniería de prompts es ineficaz ya que especifica cuántos párrafos, oraciones o palabras queremos generar. Para hacer el prompt más efectivo, especificamos explícitamente una longitud de salida esperada, como dos oraciones, y vemos esto reflejado en la salida. Para limitar la longitud de la salida, podemos usar el parámetro Max tokens, que limita el número de tokens y puede ser superado, lo que lleva respuestas incompletas o cortadas veces. Por el contrario, los límites de salida especificados través del prompt con el número máximo de palabras, oraciones o párrafos podrían ser superados, pero esto garantiza respuestas completas.Un prompt puede contener instrucciones y algunos datos de entrada para operar. Por ejemplo, en la resumido de textos, la instrucción sería resumir un texto dado y la entrada proporcionada sería el texto que necesita ser resumido. Para crear un prompt bien estructurado, colocamos las instrucciones al principio del prompt usando delimitadores como paréntesis, corchetes, comillas invertidas o cualquier otro token para especificar varias partes de entrada y mencionando en el prompt qué delimitadores se utilizan. Esta práctica permite al modelo saber exactamente dónde encontrar la entrada en el prompt. Aquí hay un ejemplo de un prompt de resumido de textos donde delimitamos el texto de entrada con comillas triples invertidas. El resultado se observa en la Figura 5.3.\nFigura 5.3: Especificando en el prompt que el texto resumir está delimitado.\n","code":""},{"path":"principios-de-la-ingeniería-de-prompts.html","id":"claridad-y-precisión-en-los-prompts","chapter":"5 Principios de la Ingeniería de Prompts","heading":"5.1 Claridad y Precisión en los Prompts","text":"Ahora profundizaremos en los principios clave de la ingeniería de prompts para crear prompts más efectivos. Al interactuar con un LLM, apuntamos prompts claros y precisos para lograr los mejores resultados. Podemos pensar en este proceso como guiar alguien de un lugar otro, donde buscamos seleccionar el camino más simple y efectivo entre varias opciones disponibles. Exploraremos 4 principios de la ingeniería de prompts, incluyendo el uso de verbos de acción apropiados, instrucciones, descripciones precisas y prompts delimitados bien estructurados.","code":""},{"path":"principios-de-la-ingeniería-de-prompts.html","id":"uso-de-verbos-de-acción-apropiados","chapter":"5 Principios de la Ingeniería de Prompts","heading":"5.2 Uso de Verbos de Acción Apropiados","text":"Al pedirle al modelo que realice ciertas tareas, opta por verbos de acción que guíen explícitamente la tarea del modelo, como escribir, completar, explicar, describir o evaluar. Por el contrario, evita usar verbos ambiguos como entender, pensar, sentir, intentar y saber, que podrían confundir la comprensión del modelo. Un prompt que le pida al modelo que piense sobre el problema de la deforestación es ineficaz. Aunque el modelo genere alguna salida sobre la deforestación, el prompt requiere una mayor claridad respecto las expectativas. Para mejorar el prompt, usamos un verbo de acción que explícitamente le diga al modelo qué hacer. Por ejemplo, le pedimos al modelo que proponga estrategias para reducir la deforestación y, en consecuencia, el modelo ofrece algunas soluciones. En la Figura 5.1 se observa claramente como mejora la respuesta utilizando verbos apropiados.\nFigura 5.1: Mejorando las respuestas utilizando verbos apropiados.\n","code":""},{"path":"principios-de-la-ingeniería-de-prompts.html","id":"instrucciones-específicas-y-detalladas","chapter":"5 Principios de la Ingeniería de Prompts","heading":"5.3 Instrucciones Específicas y Detalladas","text":"Al elaborar prompts, querremos proporcionar instrucciones específicas, descriptivas y detalladas sobre el contexto, la longitud de la salida, el formato, el estilo y la audiencia. Por ejemplo, consideramos un prompt que pide al modelo de lenguaje que nos hable sobre los perros como ineficaz porque es demasiado amplio. Sin embargo, decirle al modelo que describa el comportamiento y las características de una raza de perro específica, como los golden retrievers, permite al modelo ser más preciso con su respuesta (Figura 5.2).\nFigura 5.2: Mejorando las respuestas utilizando descripciones más precisas.\n","code":""},{"path":"principios-de-la-ingeniería-de-prompts.html","id":"descripciones-precisas","chapter":"5 Principios de la Ingeniería de Prompts","heading":"5.4 Descripciones Precisas","text":"Al elaborar prompts, trata de evitar descripciones imprecisas. Por ejemplo, pedir al modelo que genere un texto corto sobre la ingeniería de prompts es ineficaz ya que especifica cuántos párrafos, oraciones o palabras queremos generar. Para hacer el prompt más efectivo, especificamos explícitamente una longitud de salida esperada, como dos oraciones, y vemos esto reflejado en la salida. Para limitar la longitud de la salida, podemos usar el parámetro Max tokens, que limita el número de tokens y puede ser superado, lo que lleva respuestas incompletas o cortadas veces. Por el contrario, los límites de salida especificados través del prompt con el número máximo de palabras, oraciones o párrafos podrían ser superados, pero esto garantiza respuestas completas.","code":""},{"path":"principios-de-la-ingeniería-de-prompts.html","id":"estructuración-de-prompts","chapter":"5 Principios de la Ingeniería de Prompts","heading":"5.5 Estructuración de Prompts","text":"Un prompt puede contener instrucciones y algunos datos de entrada para operar. Por ejemplo, en la resumido de textos, la instrucción sería resumir un texto dado y la entrada proporcionada sería el texto que necesita ser resumido. Para crear un prompt bien estructurado, colocamos las instrucciones al principio del prompt usando delimitadores como paréntesis, corchetes, comillas invertidas o cualquier otro token para especificar varias partes de entrada y mencionando en el prompt qué delimitadores se utilizan. Esta práctica permite al modelo saber exactamente dónde encontrar la entrada en el prompt. Aquí hay un ejemplo de un prompt de resumido de textos donde delimitamos el texto de entrada con comillas triples invertidas. El resultado se observa en la Figura 5.3.\nFigura 5.3: Especificando en el prompt que el texto resumir está delimitado.\n","code":""},{"path":"creación-de-salidas-estructuradas-y-prompts-condicionales.html","id":"creación-de-salidas-estructuradas-y-prompts-condicionales","chapter":"6 Creación de Salidas Estructuradas y Prompts Condicionales","heading":"6 Creación de Salidas Estructuradas y Prompts Condicionales","text":"Nos enfocaremos ahora en crear salidas estructuradas y usar prompts condicionales. Los modelos de lenguaje generan naturalmente salidas estructuradas menos que se les instruya explícitamente. Sin embargo, hay ocasiones en las que necesitamos que la salida se presente en una tabla, lista, párrafo estructurado o un formato personalizado que elijamos. Veamos cómo tratar cada uno de estos casos.\nComenzamos con tablas. Al pedirle al modelo que genere una tabla, debemos mencionar claramente las columnas esperadas. Por ejemplo, podemos instruir al modelo para crear una tabla con 5 películas adecuadas para los amantes de la acción y definir explícitamente las columnas deseadas, título y calificación. En consecuencia, vemos cómo la salida cumple con nuestros requisitos en la Figura 6.1.\nFigura 6.1: Especificando en el prompt que queremos generar una tabla en formato html.\nOtro formato para pedir es una lista. Esta estructura es útil para enumeraciones. Por ejemplo, pedimos al modelo que genere una lista con los nombres de las cinco mejores ciudades para visitar. La salida es una lista numerada de ciudades. Debemos mencionar explícitamente los requisitos específicos sobre cómo debe formatearse la lista de salida en el prompt (Figura 6.2).\nFigura 6.2: Especificando en el prompt que queremos generar una lista en formato html.\nPodemos querer obtener párrafos con una estructura específica al generar texto. En este caso, debemos mencionar explícitamente los requisitos de formato en el prompt. Por ejemplo, podemos pedir al modelo que genere un párrafo estructurado con títulos y subtítulos claros sobre los beneficios del ejercicio. En la Figura 6.3 vemos cómo la salida está formateada con tres títulos: Salud física, Salud mental y Bienestar General.\nFigura 6.3: Generación de un párrafo estructurado con títulos y subtítulos claros en formato html.\nTambién podemos solicitar un formato de salida personalizado. Supongamos que queremos generar un título para un texto dado y presentar la salida en un estilo particular. Podemos simplificar este proceso desglosando nuestro prompt en partes distintas. Por ejemplo, comenzamos definiendo el texto de entrada, la apertura de una historia de cuento de hadas sobre un niño llamado David, y las instrucciones del modelo para generar un título apropiado. Luego especificamos la cadena de formato de salida, instruyendo al modelo para que formatee el texto y el título de una manera específica para la salida. Finalmente, combinamos las instrucciones, el formato de salida y el texto de entrada en el prompt final. La salida en la Figura 6.4 cumple con nuestros requisitos al darnos un título sobre las aventuras de David.\nFigura 6.4: Solicitando un formato de salida personalizado.\nveces podemos querer incorporar alguna lógica o condiciones en nuestros prompts. En este caso, usamos prompts condicionales. Si una condición es verdadera, realiza X, de lo contrario realiza Y. Supongamos que queremos que el modelo sugiera un título para un texto proporcionado. Sin embargo, solo queremos que el modelo haga esto si el texto está en español. Para hacer eso, mencionamos explícitamente esta condición en el prompt. Si el texto está en otro idioma, le decimos al modelo que informe los usuarios que solo entiende español. Ahora, para un texto en francés que describe mi estación favorita, la salida será “Solo entiendo español”. Podemos incorporar múltiples condiciones en nuestro prompt. Por ejemplo, podemos decirle al modelo que genere títulos solo para textos en español que contengan la palabra clave tecnología. Si el texto está escrito en español, verificamos si contiene la palabra clave. Si lo hace, el modelo sugiere un título. De lo contrario, responde con “palabra clave encontrada”. Se puede ver el resultado con las respuestas esperadas en la Figura 6.5.\nFigura 6.5: Solicitando un formato de salida personalizado.\n","code":""},{"path":"creación-de-salidas-estructuradas-y-prompts-condicionales.html","id":"generación-de-tablas","chapter":"6 Creación de Salidas Estructuradas y Prompts Condicionales","heading":"6.1 Generación de Tablas","text":"Nos enfocaremos ahora en crear salidas estructuradas y usar prompts condicionales. Los modelos de lenguaje generan naturalmente salidas estructuradas menos que se les instruya explícitamente. Sin embargo, hay ocasiones en las que necesitamos que la salida se presente en una tabla, lista, párrafo estructurado o un formato personalizado que elijamos. Veamos cómo tratar cada uno de estos casos.\nComenzamos con tablas. Al pedirle al modelo que genere una tabla, debemos mencionar claramente las columnas esperadas. Por ejemplo, podemos instruir al modelo para crear una tabla con 5 películas adecuadas para los amantes de la acción y definir explícitamente las columnas deseadas, título y calificación. En consecuencia, vemos cómo la salida cumple con nuestros requisitos en la Figura 6.1.\nFigura 6.1: Especificando en el prompt que queremos generar una tabla en formato html.\n","code":""},{"path":"creación-de-salidas-estructuradas-y-prompts-condicionales.html","id":"generación-de-listas","chapter":"6 Creación de Salidas Estructuradas y Prompts Condicionales","heading":"6.2 Generación de Listas","text":"Otro formato para pedir es una lista. Esta estructura es útil para enumeraciones. Por ejemplo, pedimos al modelo que genere una lista con los nombres de las cinco mejores ciudades para visitar. La salida es una lista numerada de ciudades. Debemos mencionar explícitamente los requisitos específicos sobre cómo debe formatearse la lista de salida en el prompt (Figura 6.2).\nFigura 6.2: Especificando en el prompt que queremos generar una lista en formato html.\n","code":""},{"path":"creación-de-salidas-estructuradas-y-prompts-condicionales.html","id":"párrafos-estructurados","chapter":"6 Creación de Salidas Estructuradas y Prompts Condicionales","heading":"6.3 Párrafos Estructurados","text":"Podemos querer obtener párrafos con una estructura específica al generar texto. En este caso, debemos mencionar explícitamente los requisitos de formato en el prompt. Por ejemplo, podemos pedir al modelo que genere un párrafo estructurado con títulos y subtítulos claros sobre los beneficios del ejercicio. En la Figura 6.3 vemos cómo la salida está formateada con tres títulos: Salud física, Salud mental y Bienestar General.\nFigura 6.3: Generación de un párrafo estructurado con títulos y subtítulos claros en formato html.\n","code":""},{"path":"creación-de-salidas-estructuradas-y-prompts-condicionales.html","id":"formatos-personalizados","chapter":"6 Creación de Salidas Estructuradas y Prompts Condicionales","heading":"6.4 Formatos Personalizados","text":"También podemos solicitar un formato de salida personalizado. Supongamos que queremos generar un título para un texto dado y presentar la salida en un estilo particular. Podemos simplificar este proceso desglosando nuestro prompt en partes distintas. Por ejemplo, comenzamos definiendo el texto de entrada, la apertura de una historia de cuento de hadas sobre un niño llamado David, y las instrucciones del modelo para generar un título apropiado. Luego especificamos la cadena de formato de salida, instruyendo al modelo para que formatee el texto y el título de una manera específica para la salida. Finalmente, combinamos las instrucciones, el formato de salida y el texto de entrada en el prompt final. La salida en la Figura 6.4 cumple con nuestros requisitos al darnos un título sobre las aventuras de David.\nFigura 6.4: Solicitando un formato de salida personalizado.\n","code":""},{"path":"creación-de-salidas-estructuradas-y-prompts-condicionales.html","id":"prompts-condicionales","chapter":"6 Creación de Salidas Estructuradas y Prompts Condicionales","heading":"6.5 Prompts Condicionales","text":"veces podemos querer incorporar alguna lógica o condiciones en nuestros prompts. En este caso, usamos prompts condicionales. Si una condición es verdadera, realiza X, de lo contrario realiza Y. Supongamos que queremos que el modelo sugiera un título para un texto proporcionado. Sin embargo, solo queremos que el modelo haga esto si el texto está en español. Para hacer eso, mencionamos explícitamente esta condición en el prompt. Si el texto está en otro idioma, le decimos al modelo que informe los usuarios que solo entiende español. Ahora, para un texto en francés que describe mi estación favorita, la salida será “Solo entiendo español”. Podemos incorporar múltiples condiciones en nuestro prompt. Por ejemplo, podemos decirle al modelo que genere títulos solo para textos en español que contengan la palabra clave tecnología. Si el texto está escrito en español, verificamos si contiene la palabra clave. Si lo hace, el modelo sugiere un título. De lo contrario, responde con “palabra clave encontrada”. Se puede ver el resultado con las respuestas esperadas en la Figura 6.5.\nFigura 6.5: Solicitando un formato de salida personalizado.\n","code":""},{"path":"técnicas-de-prompting-avanzadas.html","id":"técnicas-de-prompting-avanzadas","chapter":"7 Técnicas de Prompting Avanzadas","heading":"7 Técnicas de Prompting Avanzadas","text":"Exploremos el prompting de pocos disparos y sus diferentes aplicaciones. El prompting de fusión es una técnica en la que se presentan ejemplos los modelos de lenguaje para que aprendan dentro del prompt. Para hacer esto, formulamos un prompt que contiene pares de pregunta y respuesta de ejemplo y la pregunta la que queremos que el modelo responda. Alimentamos este prompt al modelo y obtenemos la respuesta nuestra pregunta cambio. Con este enfoque, el modelo aprende cómo responder la pregunta dada partir de los ejemplos (7.1). El nombre de la técnica varía dependiendo del número de ejemplos que proporcionamos. Cuando hay ejemplos proporcionados, estamos utilizando el prompting de cero disparos. Con un ejemplo, estamos utilizando el prompting de un disparo y con más de un ejemplo estamos utilizando el prompting de pocos disparos. Exploremos cada uno de ellos en más detalle.\nFigura 7.1: Ejemplo de prompting con varios disparos. (Hecho con Python)\nEn el prompting de cero disparos, proporcionamos un prompt al modelo sin ejemplos explícitos. Se espera que el modelo genere una respuesta basada en su conocimiento existente. Esta técnica es ideal para tareas rápidas y sencillas. Por ejemplo, usamos el prompting de cero disparos cuando pedimos al modelo que defina la ingeniería de prompts sin proporcionar ejemplos para guiar la salida tal y como se muestra en la Figura 7.2.\nFigura 7.2: Ejemplo de prompting con cero disparos.\nEn el prompting de un disparo, proporcionamos un único ejemplo de pregunta y respuesta al modelo, lo que le permite aprender de esa única entrada. Esta técnica es ideal cuando queremos que la salida del modelo siga un formato o estilo específico y consistente. Por ejemplo, supongamos que queremos que el modelo sume 3 números como 3, 5 y 6, con la salida escrita como una ecuación como 3 + 5 + 6 = 14. Usamos este estilo en el ejemplo proporcionado y la respuesta para cualquier nuevo número seguirá el mismo estilo. Para aclarar esta idea, usemos el mismo prompt y ejemplo, pero con la salida siendo una oración como “la suma de tres, cinco y seis es 14”. La respuesta nuestra segunda pregunta ha seguido el mismo formato como se ve en la Figura 7.3.\nFigura 7.3: Ejemplo de prompting con un disparo.\nFinalmente, en el prompting de varios disparos, proporcionamos más de un ejemplo al modelo. Esta técnica es poderosa cuando queremos que el modelo realice tareas contextuales que requieren más información que el prompting de un disparo puede proporcionar. Por ejemplo, para realizar un análisis de sentimientos, podemos dar al modelo textos de muestra sobre si los comentarios de los productos son positivos o negativos junto con su clasificación y luego pedirle que clasifique un nuevo texto según lo que aprendió (Figura 7.4).\nFigura 7.4: Ejemplo de prompting varios disparos.\nAlgunas consideraciones al tratar con el prompting de varios disparos. Debemos considerar la complejidad de la tarea para seleccionar el número óptimo de disparos para proporcionar al modelo. Menos disparos podrían lograr tareas básicas. Por ejemplo, un solo ejemplo podría ser suficiente para controlar la estructura de la salida. Para tareas más complejas como la clasificación de texto en múltiples categorías, es importante incorporar ejemplos diversos asegurando al menos un ejemplo para cada clase para guiar eficazmente la salida del modelo.","code":""},{"path":"técnicas-de-prompting-avanzadas.html","id":"prompting-de-pocos-disparos","chapter":"7 Técnicas de Prompting Avanzadas","heading":"7.1 Prompting de Pocos Disparos","text":"Exploremos el prompting de pocos disparos y sus diferentes aplicaciones. El prompting de fusión es una técnica en la que se presentan ejemplos los modelos de lenguaje para que aprendan dentro del prompt. Para hacer esto, formulamos un prompt que contiene pares de pregunta y respuesta de ejemplo y la pregunta la que queremos que el modelo responda. Alimentamos este prompt al modelo y obtenemos la respuesta nuestra pregunta cambio. Con este enfoque, el modelo aprende cómo responder la pregunta dada partir de los ejemplos (7.1). El nombre de la técnica varía dependiendo del número de ejemplos que proporcionamos. Cuando hay ejemplos proporcionados, estamos utilizando el prompting de cero disparos. Con un ejemplo, estamos utilizando el prompting de un disparo y con más de un ejemplo estamos utilizando el prompting de pocos disparos. Exploremos cada uno de ellos en más detalle.\nFigura 7.1: Ejemplo de prompting con varios disparos. (Hecho con Python)\n","code":""},{"path":"técnicas-de-prompting-avanzadas.html","id":"prompting-de-cero-disparos","chapter":"7 Técnicas de Prompting Avanzadas","heading":"7.2 Prompting de Cero Disparos","text":"En el prompting de cero disparos, proporcionamos un prompt al modelo sin ejemplos explícitos. Se espera que el modelo genere una respuesta basada en su conocimiento existente. Esta técnica es ideal para tareas rápidas y sencillas. Por ejemplo, usamos el prompting de cero disparos cuando pedimos al modelo que defina la ingeniería de prompts sin proporcionar ejemplos para guiar la salida tal y como se muestra en la Figura 7.2.\nFigura 7.2: Ejemplo de prompting con cero disparos.\n","code":""},{"path":"técnicas-de-prompting-avanzadas.html","id":"prompting-de-un-disparo","chapter":"7 Técnicas de Prompting Avanzadas","heading":"7.3 Prompting de Un Disparo","text":"En el prompting de un disparo, proporcionamos un único ejemplo de pregunta y respuesta al modelo, lo que le permite aprender de esa única entrada. Esta técnica es ideal cuando queremos que la salida del modelo siga un formato o estilo específico y consistente. Por ejemplo, supongamos que queremos que el modelo sume 3 números como 3, 5 y 6, con la salida escrita como una ecuación como 3 + 5 + 6 = 14. Usamos este estilo en el ejemplo proporcionado y la respuesta para cualquier nuevo número seguirá el mismo estilo. Para aclarar esta idea, usemos el mismo prompt y ejemplo, pero con la salida siendo una oración como “la suma de tres, cinco y seis es 14”. La respuesta nuestra segunda pregunta ha seguido el mismo formato como se ve en la Figura 7.3.\nFigura 7.3: Ejemplo de prompting con un disparo.\n","code":""},{"path":"técnicas-de-prompting-avanzadas.html","id":"prompting-de-varios-disparos","chapter":"7 Técnicas de Prompting Avanzadas","heading":"7.4 Prompting de Varios Disparos","text":"Finalmente, en el prompting de varios disparos, proporcionamos más de un ejemplo al modelo. Esta técnica es poderosa cuando queremos que el modelo realice tareas contextuales que requieren más información que el prompting de un disparo puede proporcionar. Por ejemplo, para realizar un análisis de sentimientos, podemos dar al modelo textos de muestra sobre si los comentarios de los productos son positivos o negativos junto con su clasificación y luego pedirle que clasifique un nuevo texto según lo que aprendió (Figura 7.4).\nFigura 7.4: Ejemplo de prompting varios disparos.\n","code":""},{"path":"técnicas-de-prompting-avanzadas.html","id":"consideraciones-al-usar-prompting-de-varios-disparos","chapter":"7 Técnicas de Prompting Avanzadas","heading":"7.5 Consideraciones al Usar Prompting de Varios Disparos","text":"Algunas consideraciones al tratar con el prompting de varios disparos. Debemos considerar la complejidad de la tarea para seleccionar el número óptimo de disparos para proporcionar al modelo. Menos disparos podrían lograr tareas básicas. Por ejemplo, un solo ejemplo podría ser suficiente para controlar la estructura de la salida. Para tareas más complejas como la clasificación de texto en múltiples categorías, es importante incorporar ejemplos diversos asegurando al menos un ejemplo para cada clase para guiar eficazmente la salida del modelo.","code":""},{"path":"prompting-de-varios-pasos.html","id":"prompting-de-varios-pasos","chapter":"8 Prompting de Varios Pasos","heading":"8 Prompting de Varios Pasos","text":"Exploremos el prompting de varios pasos, que guía el comportamiento del modelo para generar salidas efectivas. El prompting de varios pasos es una técnica donde desglosamos un objetivo final en una serie de pasos pequeños. El modelo tiene que pasar por cada paso antes de dar la salida final. Estos pasos facilitan las cosas para el modelo y aumentan las probabilidades de éxito. Las tareas secuenciales como generar un texto coherente partir de un esquema dado, se benefician de los prompts de varios pasos ya que menudo necesitan completar una serie de pasos en un orden específico. Las tareas cognitivas como evaluar la corrección de una solución también utilizan prompts de varios pasos ya que implican procesamiento cognitivo, resolución de problemas y toma de decisiones. Podemos pensar en los prompts de varios pasos como mapas del tesoro, así como un mapa del tesoro proporciona una secuencia de pistas e instrucciones para descubrir tesoros ocultos, un prompt de varios pasos descompone una tarea compleja en pasos más pequeños y manejables que el modelo debe seguir para alcanzar el resultado deseado.Supongamos que queremos escribir un blog de viajes. Podríamos comenzar con un prompt de un solo paso, pidiendo al modelo que cree todo el blog sin detalles adicionales. En este ejemplo, el modelo generará texto sobre un viaje aleatorio través de un país, Islandia, con un itinerario día por día. Para dar más detalles sobre lo que debe cubrirse en el blog, creamos un prompt de varios pasos que pide al modelo que lo escriba en tres pasos: presentar el destino, compartir aventuras personales y resumir el viaje. Nótese que la elección del destino es insignificante y el enfoque está solo en la estructura del blog. El modelo genera un blog de viajes coherente según nuestras instrucciones, con una introducción Japón, una aventura y el resumen. Ver Figura 8.1.\nFigura 8.1: Ejemplo de prompting de varios pasos.\nOtra aplicación del prompting de varios pasos son las tareas cognitivas como analizar la corrección de una solución. Supongamos que necesitamos verificar la corrección de un código en Python que contiene funciones que implementan cálculos básicos como suma, resta, multiplicación y división. Supongamos que la cadena del calculador contiene el contenido de los archivos que queremos verificar. Como se observa, incluye funciones que aceptan 2 números como entrada y realizan suma, resta, multiplicación o división, devolviendo los resultados correspondientes. Como punto de partida, podríamos considerar elaborar un prompt de un solo paso que encargue al modelo evaluar la corrección del código proporcionado. Aunque el modelo responde con un “sí”, diciéndonos que el código es correcto, sabemos cómo se realizó la evaluación. Podríamos necesitar evaluar según criterios específicos o conocimientos del dominio. Por ejemplo, aunque la sintaxis es correcta, la función de división maneja la división por cero, y podríamos querer que esto se considere en la evaluación. Para lograr eso, usamos un prompt de varios pasos donde en el paso uno verificamos la corrección de la sintaxis y en el paso dos verificamos si se maneja la división por cero. Después de estos cambios, la salida del modelo da retroalimentación sobre cada paso y nos dice que la sintaxis es correcta, pero la división por cero se maneja.Revisemos las diferencias entre los prompts de varios pasos y los prompts de cadena de pensamiento. Mientras que los pasos y los disparos juegan roles cruciales en el control del comportamiento del modelo, los pasos son instrucciones que le dicen explícitamente al modelo qué hacer. Actúan como una hoja de ruta para el modelo al proporcionar orientación específica.Los disparos son preguntas y respuestas de ejemplo de las que el modelo aprende. Demuestran cómo el modelo debe responder ciertas entradas. El modelo observa estos ejemplos y aprende generalizar partir de ellos.","code":""},{"path":"prompting-de-varios-pasos.html","id":"introducción-al-prompting-de-varios-pasos","chapter":"8 Prompting de Varios Pasos","heading":"8.1 Introducción al Prompting de Varios Pasos","text":"Exploremos el prompting de varios pasos, que guía el comportamiento del modelo para generar salidas efectivas. El prompting de varios pasos es una técnica donde desglosamos un objetivo final en una serie de pasos pequeños. El modelo tiene que pasar por cada paso antes de dar la salida final. Estos pasos facilitan las cosas para el modelo y aumentan las probabilidades de éxito. Las tareas secuenciales como generar un texto coherente partir de un esquema dado, se benefician de los prompts de varios pasos ya que menudo necesitan completar una serie de pasos en un orden específico. Las tareas cognitivas como evaluar la corrección de una solución también utilizan prompts de varios pasos ya que implican procesamiento cognitivo, resolución de problemas y toma de decisiones. Podemos pensar en los prompts de varios pasos como mapas del tesoro, así como un mapa del tesoro proporciona una secuencia de pistas e instrucciones para descubrir tesoros ocultos, un prompt de varios pasos descompone una tarea compleja en pasos más pequeños y manejables que el modelo debe seguir para alcanzar el resultado deseado.","code":""},{"path":"prompting-de-varios-pasos.html","id":"ejemplos-de-prompting-de-varios-pasos","chapter":"8 Prompting de Varios Pasos","heading":"8.2 Ejemplos de Prompting de Varios Pasos","text":"Supongamos que queremos escribir un blog de viajes. Podríamos comenzar con un prompt de un solo paso, pidiendo al modelo que cree todo el blog sin detalles adicionales. En este ejemplo, el modelo generará texto sobre un viaje aleatorio través de un país, Islandia, con un itinerario día por día. Para dar más detalles sobre lo que debe cubrirse en el blog, creamos un prompt de varios pasos que pide al modelo que lo escriba en tres pasos: presentar el destino, compartir aventuras personales y resumir el viaje. Nótese que la elección del destino es insignificante y el enfoque está solo en la estructura del blog. El modelo genera un blog de viajes coherente según nuestras instrucciones, con una introducción Japón, una aventura y el resumen. Ver Figura 8.1.\nFigura 8.1: Ejemplo de prompting de varios pasos.\n","code":""},{"path":"prompting-de-varios-pasos.html","id":"aplicaciones-cognitivas-del-prompting-de-varios-pasos","chapter":"8 Prompting de Varios Pasos","heading":"8.3 Aplicaciones Cognitivas del Prompting de Varios Pasos","text":"Otra aplicación del prompting de varios pasos son las tareas cognitivas como analizar la corrección de una solución. Supongamos que necesitamos verificar la corrección de un código en Python que contiene funciones que implementan cálculos básicos como suma, resta, multiplicación y división. Supongamos que la cadena del calculador contiene el contenido de los archivos que queremos verificar. Como se observa, incluye funciones que aceptan 2 números como entrada y realizan suma, resta, multiplicación o división, devolviendo los resultados correspondientes. Como punto de partida, podríamos considerar elaborar un prompt de un solo paso que encargue al modelo evaluar la corrección del código proporcionado. Aunque el modelo responde con un “sí”, diciéndonos que el código es correcto, sabemos cómo se realizó la evaluación. Podríamos necesitar evaluar según criterios específicos o conocimientos del dominio. Por ejemplo, aunque la sintaxis es correcta, la función de división maneja la división por cero, y podríamos querer que esto se considere en la evaluación. Para lograr eso, usamos un prompt de varios pasos donde en el paso uno verificamos la corrección de la sintaxis y en el paso dos verificamos si se maneja la división por cero. Después de estos cambios, la salida del modelo da retroalimentación sobre cada paso y nos dice que la sintaxis es correcta, pero la división por cero se maneja.","code":""},{"path":"prompting-de-varios-pasos.html","id":"diferencias-entre-prompts-de-varios-pasos-y-cadena-de-pensamiento","chapter":"8 Prompting de Varios Pasos","heading":"8.4 Diferencias entre Prompts de Varios Pasos y Cadena de Pensamiento","text":"Revisemos las diferencias entre los prompts de varios pasos y los prompts de cadena de pensamiento. Mientras que los pasos y los disparos juegan roles cruciales en el control del comportamiento del modelo, los pasos son instrucciones que le dicen explícitamente al modelo qué hacer. Actúan como una hoja de ruta para el modelo al proporcionar orientación específica.Los disparos son preguntas y respuestas de ejemplo de las que el modelo aprende. Demuestran cómo el modelo debe responder ciertas entradas. El modelo observa estos ejemplos y aprende generalizar partir de ellos.","code":""},{"path":"prompting-de-cadena-de-pensamiento.html","id":"prompting-de-cadena-de-pensamiento","chapter":"9 Prompting de Cadena de Pensamiento","heading":"9 Prompting de Cadena de Pensamiento","text":"El prompting de cadena de pensamiento es una técnica que requiere que los modelos de lenguaje presenten una serie de pasos de razonamiento referidos como pensamientos antes de proporcionar una respuesta final. En otras palabras, los modelos de lenguaje deben explicar cómo llegaron una conclusión. Esta técnica es particularmente valiosa al tratar tareas de razonamiento complejo. Además, ayuda reducir errores del modelo ya que el razonamiento ocurre paso paso.Para entender el poder de los prompts de cadena de pensamiento, comparemoslos con los prompts estándar usando un problema matemático. Supongamos que queremos determinar cuántos libros tiene una persona, dados su número existente de libros y sus decisiones de préstamo y compra. Si pedimos al modelo que muestre la respuesta, nos dará un número. Sin embargo, podemos estar seguros de su corrección sin saber cómo se generó este número. Para tratar esto, usamos un prompt de cadena de pensamiento pidiendo al modelo que proporcione esta explicación paso paso. Ahora el modelo resuelve el problema un paso la vez antes de dar la respuesta final. Desglosando la solución en cinco pasos. En la Figura 9.1 se pueden ver todos los pasos y solo la solución con lo cual estamos seguros de que la respuesta es correcta.\nFigura 9.1: Ejemplo de prompting de varios pasos.\nPodemos usar prompts de varios disparos para obtener razonamientos de cadena de pensamiento. En lugar de instruir explícitamente al modelo para que genere pasos de razonamiento, proporcionamos ejemplos de lo que deben contener las respuestas. Por ejemplo, consideremos la tarea de evaluar si un grupo de números impares suma un número par. Proporcionamos una pregunta y respuesta de ejemplo para el modelo. La respuesta aclara los pasos requeridos, encontrando los números impares y luego sumándolos para determinar si la afirmación es verdadera o falsa. Luego proporcionamos una nueva pregunta y dejamos una para que el modelo responda. Combinamos el ejemplo y la pregunta para obtener el prompt final. Como podemos ver, el modelo sigue una lógica similar para generar su respuesta. Ver Figura 9.2.\nFigura 9.2: Ejemplo de prompting Varios Disparos para Cadena de Pensamiento.\nEstudiemos la diferencia entre los prompts de varios pasos y los prompts de cadena de pensamiento. Con los prompts de varios pasos, los diversos pasos de la tarea están directamente incorporados en el prompt mismo, guiando el comportamiento del LLM. Los prompts de cadena de pensamiento adoptan un enfoque diferente al instruir al modelo para que genere pasos intermedios o pensamientos en su salida mientras resuelve el problema. Esto ayuda obtener información sobre la toma de decisiones del modelo. Una limitación del prompting de cadena de pensamiento es que un pensamiento con razonamiento defectuoso llevará un resultado fallido.","code":""},{"path":"prompting-de-cadena-de-pensamiento.html","id":"introducción-al-prompting-de-cadena-de-pensamiento","chapter":"9 Prompting de Cadena de Pensamiento","heading":"9.1 Introducción al Prompting de Cadena de Pensamiento","text":"El prompting de cadena de pensamiento es una técnica que requiere que los modelos de lenguaje presenten una serie de pasos de razonamiento referidos como pensamientos antes de proporcionar una respuesta final. En otras palabras, los modelos de lenguaje deben explicar cómo llegaron una conclusión. Esta técnica es particularmente valiosa al tratar tareas de razonamiento complejo. Además, ayuda reducir errores del modelo ya que el razonamiento ocurre paso paso.","code":""},{"path":"prompting-de-cadena-de-pensamiento.html","id":"ejemplo-de-uso-del-prompting-de-cadena-de-pensamiento","chapter":"9 Prompting de Cadena de Pensamiento","heading":"9.2 Ejemplo de Uso del Prompting de Cadena de Pensamiento","text":"Para entender el poder de los prompts de cadena de pensamiento, comparemoslos con los prompts estándar usando un problema matemático. Supongamos que queremos determinar cuántos libros tiene una persona, dados su número existente de libros y sus decisiones de préstamo y compra. Si pedimos al modelo que muestre la respuesta, nos dará un número. Sin embargo, podemos estar seguros de su corrección sin saber cómo se generó este número. Para tratar esto, usamos un prompt de cadena de pensamiento pidiendo al modelo que proporcione esta explicación paso paso. Ahora el modelo resuelve el problema un paso la vez antes de dar la respuesta final. Desglosando la solución en cinco pasos. En la Figura 9.1 se pueden ver todos los pasos y solo la solución con lo cual estamos seguros de que la respuesta es correcta.\nFigura 9.1: Ejemplo de prompting de varios pasos.\n","code":""},{"path":"prompting-de-cadena-de-pensamiento.html","id":"uso-de-prompting-de-varios-disparos-para-cadena-de-pensamiento","chapter":"9 Prompting de Cadena de Pensamiento","heading":"9.3 Uso de Prompting de Varios Disparos para Cadena de Pensamiento","text":"Podemos usar prompts de varios disparos para obtener razonamientos de cadena de pensamiento. En lugar de instruir explícitamente al modelo para que genere pasos de razonamiento, proporcionamos ejemplos de lo que deben contener las respuestas. Por ejemplo, consideremos la tarea de evaluar si un grupo de números impares suma un número par. Proporcionamos una pregunta y respuesta de ejemplo para el modelo. La respuesta aclara los pasos requeridos, encontrando los números impares y luego sumándolos para determinar si la afirmación es verdadera o falsa. Luego proporcionamos una nueva pregunta y dejamos una para que el modelo responda. Combinamos el ejemplo y la pregunta para obtener el prompt final. Como podemos ver, el modelo sigue una lógica similar para generar su respuesta. Ver Figura 9.2.\nFigura 9.2: Ejemplo de prompting Varios Disparos para Cadena de Pensamiento.\n","code":""},{"path":"prompting-de-cadena-de-pensamiento.html","id":"diferencias-entre-prompting-de-varios-pasos-y-cadena-de-pensamiento","chapter":"9 Prompting de Cadena de Pensamiento","heading":"9.4 Diferencias entre Prompting de Varios Pasos y Cadena de Pensamiento","text":"Estudiemos la diferencia entre los prompts de varios pasos y los prompts de cadena de pensamiento. Con los prompts de varios pasos, los diversos pasos de la tarea están directamente incorporados en el prompt mismo, guiando el comportamiento del LLM. Los prompts de cadena de pensamiento adoptan un enfoque diferente al instruir al modelo para que genere pasos intermedios o pensamientos en su salida mientras resuelve el problema. Esto ayuda obtener información sobre la toma de decisiones del modelo. Una limitación del prompting de cadena de pensamiento es que un pensamiento con razonamiento defectuoso llevará un resultado fallido.","code":""},{"path":"prompting-de-autocoherencia-e-ingeniería-de-prompts-iterativa.html","id":"prompting-de-autocoherencia-e-ingeniería-de-prompts-iterativa","chapter":"10 Prompting de Autocoherencia e Ingeniería de Prompts Iterativa","heading":"10 Prompting de Autocoherencia e Ingeniería de Prompts Iterativa","text":"Aquí es donde entran los prompts de auto coherencia. El prompting de auto coherencia es una técnica que genera múltiples cadenas de pensamientos al solicitar al modelo varias veces para obtener diferentes salidas. La salida final se obtiene mediante una votación por mayoría, donde la salida o respuesta más comúnmente ocurrida entre las salidas individuales se selecciona como el resultado final.Aunque podemos implementar esta técnica solicitando manualmente al modelo varias veces y comparando los resultados, discutamos un prompt que podemos usar en su lugar. Definimos una instrucción de auto coherencia donde pedimos al modelo que imagine que varios expertos independientes están respondiendo una pregunta y la respuesta final se obtiene por mayoría de votos. Para resolver este tipo de prompts vamos usar la aplicación 2, tal y como se ve en la Ver Figura 10.1. tiene dos entradas, la del usuario, que es la que hemos venido utilizando hasta ahora y luego tiene otra entrada llamada SISTEMA DE PROMPT que puede hacer el rol de Sistema o de Asistente.\nFigura 10.1: Aplicación 2: Usuario/(Sistema o Asistente).\nEste prompt debe especificar explícitamente el número de expertos involucrados, en este caso 3. Luego definimos la pregunta y el problema resolver, un problema matemático donde necesitamos determinar el número de autos en un estacionamiento. Creamos el prompt final combinando la instrucción de auto coherencia y el problema resolver. En la salida, el modelo da la respuesta de cada experto y agrega el resultado para proporcionar una respuesta final.Pregunta:Si hay 10 autos en el estacionamiento y llegan 3 autos más. Sale la mitad del número original de coches. Entonces, la mitad del número actual de coches llegar. ¿Cuántos coches hay en el aparcamiento?Dado que los tres expertos obtuvieron el número 12, la respuesta final es 12 tal y como se puede ver en la Figura 10.2. Se puede ver que para responder la pregunta situada en la entrada del Usuario, tiene en cuenta la información que tiene guardada en el Sistema.\nFigura 10.2: Resolver el problema del auto alimentando el Sistema de Prompt.\nAdentrémonos en la ingeniería de prompts iterativa y refinamiento, un paradigma que se puede aplicar cualquier tipo de prompt que hayamos cubierto anteriormente. pesar de las diversas técnicas de ingeniería de prompts que hemos aprendido, siempre podemos diseñar el prompt perfecto en un solo intento. La ingeniería de prompts es un proceso iterativo donde construimos un prompt, lo alimentamos al modelo, observamos y analizamos la salida y, en consecuencia, reiteramos para mejorar el prompt.Crear el prompt.Alimentar el modelo.Observar y analizar la salida, si es correcta paramos, si vamos al punto 4.Modificar el prompt de forma adecuada y pasar al paso 2.veces debemos refinar nuestros prompts porque el modelo entiende claramente lo que estamos pidiendo. Por ejemplo, podríamos comenzar pidiendo al modelo que genere una hoja de cálculo de Excel que contenga los nombres de cinco estudiantes junto con sus calificaciones. Sin embargo, el modelo podría asumir que estamos pidiendo una hoja de cálculo real que puede generar. Para refinar el prompt, le pedimos al modelo que genere una tabla que podamos copiar Excel. Como resultado, el modelo nos da la salida deseada. Ver Figura 10.3.\nFigura 10.3: Proceso iterativo y refinamiento del prompt.\nLa ingeniería de prompts iterativa se limita prompts estándar. Supongamos que queremos que el modelo clasifique descripciones meteorológicas usando un prompt de pocos disparos como ejemplo. Nuestro prompt inicial podría contener descripciones meteorológicas simples junto con sus clasificaciones, y la nueva descripción al final que el modelo debe clasificar. Como podemos ver, el modelo clasifica con precisión como nevado incluso sin proporcionar ejemplos clasificados como nevado. Pero, ¿qué pasaría si la descripción que queremos clasificar es algo como “El viento del cambio trajo una brisa refrescante las operaciones de la empresa”? El modelo clasifica erróneamente este ejemplo como ventoso, aunque esté relacionado con el clima en absoluto. Para refinar el prompt de pocos disparos, refinamos sus ejemplos. En este caso, agregamos un ejemplo, como “El clima político en el país”, con tormentoso, y lo asignamos la clase desconocido. Como resultado, el modelo clasifica correctamente la descripción anterior como desconocido porque ahora sabe cómo clasificar tales casos. El refinamiento de prompts es común en diferentes tipos de prompts. Así como refinamos los ejemplos con prompts de pocos disparos, refinamos los pasos en prompts de varios pasos y la cadena de pensamiento y los prompts de autocoherencia. Refinamos la descripción del problema. El modelo podría generar respuestas incorrectas debido la falta de conocimiento del dominio, pero aprenderemos cómo tratar eso en capítulos posteriores.","code":""},{"path":"prompting-de-autocoherencia-e-ingeniería-de-prompts-iterativa.html","id":"introducción-al-prompting-de-auto-coherencia","chapter":"10 Prompting de Autocoherencia e Ingeniería de Prompts Iterativa","heading":"10.1 Introducción al Prompting de Auto coherencia","text":"Aquí es donde entran los prompts de auto coherencia. El prompting de auto coherencia es una técnica que genera múltiples cadenas de pensamientos al solicitar al modelo varias veces para obtener diferentes salidas. La salida final se obtiene mediante una votación por mayoría, donde la salida o respuesta más comúnmente ocurrida entre las salidas individuales se selecciona como el resultado final.","code":""},{"path":"prompting-de-autocoherencia-e-ingeniería-de-prompts-iterativa.html","id":"ejemplo-de-uso-del-prompting-de-autocoherencia","chapter":"10 Prompting de Autocoherencia e Ingeniería de Prompts Iterativa","heading":"10.2 Ejemplo de Uso del Prompting de Autocoherencia","text":"Aunque podemos implementar esta técnica solicitando manualmente al modelo varias veces y comparando los resultados, discutamos un prompt que podemos usar en su lugar. Definimos una instrucción de auto coherencia donde pedimos al modelo que imagine que varios expertos independientes están respondiendo una pregunta y la respuesta final se obtiene por mayoría de votos. Para resolver este tipo de prompts vamos usar la aplicación 2, tal y como se ve en la Ver Figura 10.1. tiene dos entradas, la del usuario, que es la que hemos venido utilizando hasta ahora y luego tiene otra entrada llamada SISTEMA DE PROMPT que puede hacer el rol de Sistema o de Asistente.\nFigura 10.1: Aplicación 2: Usuario/(Sistema o Asistente).\nEste prompt debe especificar explícitamente el número de expertos involucrados, en este caso 3. Luego definimos la pregunta y el problema resolver, un problema matemático donde necesitamos determinar el número de autos en un estacionamiento. Creamos el prompt final combinando la instrucción de auto coherencia y el problema resolver. En la salida, el modelo da la respuesta de cada experto y agrega el resultado para proporcionar una respuesta final.Pregunta:Si hay 10 autos en el estacionamiento y llegan 3 autos más. Sale la mitad del número original de coches. Entonces, la mitad del número actual de coches llegar. ¿Cuántos coches hay en el aparcamiento?Dado que los tres expertos obtuvieron el número 12, la respuesta final es 12 tal y como se puede ver en la Figura 10.2. Se puede ver que para responder la pregunta situada en la entrada del Usuario, tiene en cuenta la información que tiene guardada en el Sistema.\nFigura 10.2: Resolver el problema del auto alimentando el Sistema de Prompt.\n","code":""},{"path":"prompting-de-autocoherencia-e-ingeniería-de-prompts-iterativa.html","id":"introducción-a-la-ingeniería-de-prompts-iterativa","chapter":"10 Prompting de Autocoherencia e Ingeniería de Prompts Iterativa","heading":"10.3 Introducción a la Ingeniería de Prompts Iterativa","text":"Adentrémonos en la ingeniería de prompts iterativa y refinamiento, un paradigma que se puede aplicar cualquier tipo de prompt que hayamos cubierto anteriormente. pesar de las diversas técnicas de ingeniería de prompts que hemos aprendido, siempre podemos diseñar el prompt perfecto en un solo intento. La ingeniería de prompts es un proceso iterativo donde construimos un prompt, lo alimentamos al modelo, observamos y analizamos la salida y, en consecuencia, reiteramos para mejorar el prompt.Crear el prompt.Alimentar el modelo.Observar y analizar la salida, si es correcta paramos, si vamos al punto 4.Modificar el prompt de forma adecuada y pasar al paso 2.","code":""},{"path":"prompting-de-autocoherencia-e-ingeniería-de-prompts-iterativa.html","id":"ejemplo-de-refinamiento-de-prompts","chapter":"10 Prompting de Autocoherencia e Ingeniería de Prompts Iterativa","heading":"10.4 Ejemplo de Refinamiento de Prompts","text":"veces debemos refinar nuestros prompts porque el modelo entiende claramente lo que estamos pidiendo. Por ejemplo, podríamos comenzar pidiendo al modelo que genere una hoja de cálculo de Excel que contenga los nombres de cinco estudiantes junto con sus calificaciones. Sin embargo, el modelo podría asumir que estamos pidiendo una hoja de cálculo real que puede generar. Para refinar el prompt, le pedimos al modelo que genere una tabla que podamos copiar Excel. Como resultado, el modelo nos da la salida deseada. Ver Figura 10.3.\nFigura 10.3: Proceso iterativo y refinamiento del prompt.\n","code":""},{"path":"prompting-de-autocoherencia-e-ingeniería-de-prompts-iterativa.html","id":"refinamiento-de-prompts-de-pocos-disparos","chapter":"10 Prompting de Autocoherencia e Ingeniería de Prompts Iterativa","heading":"10.5 Refinamiento de Prompts de Pocos Disparos","text":"La ingeniería de prompts iterativa se limita prompts estándar. Supongamos que queremos que el modelo clasifique descripciones meteorológicas usando un prompt de pocos disparos como ejemplo. Nuestro prompt inicial podría contener descripciones meteorológicas simples junto con sus clasificaciones, y la nueva descripción al final que el modelo debe clasificar. Como podemos ver, el modelo clasifica con precisión como nevado incluso sin proporcionar ejemplos clasificados como nevado. Pero, ¿qué pasaría si la descripción que queremos clasificar es algo como “El viento del cambio trajo una brisa refrescante las operaciones de la empresa”? El modelo clasifica erróneamente este ejemplo como ventoso, aunque esté relacionado con el clima en absoluto. Para refinar el prompt de pocos disparos, refinamos sus ejemplos. En este caso, agregamos un ejemplo, como “El clima político en el país”, con tormentoso, y lo asignamos la clase desconocido. Como resultado, el modelo clasifica correctamente la descripción anterior como desconocido porque ahora sabe cómo clasificar tales casos. El refinamiento de prompts es común en diferentes tipos de prompts. Así como refinamos los ejemplos con prompts de pocos disparos, refinamos los pasos en prompts de varios pasos y la cadena de pensamiento y los prompts de autocoherencia. Refinamos la descripción del problema. El modelo podría generar respuestas incorrectas debido la falta de conocimiento del dominio, pero aprenderemos cómo tratar eso en capítulos posteriores.","code":""},{"path":"aplicaciones-comerciales-de-la-ingeniería-de-prompts.html","id":"aplicaciones-comerciales-de-la-ingeniería-de-prompts","chapter":"11 Aplicaciones Comerciales de la Ingeniería de Prompts","heading":"11 Aplicaciones Comerciales de la Ingeniería de Prompts","text":"Ahora que estamos cómodos con los principios y estrategias de la ingeniería de prompts, es hora de poner este conocimiento en práctica para diversas aplicaciones comerciales. Nos enfocaremos ahora en desarrollar prompts efectivos para el resumen y expansión de texto. El resumen de texto consiste en condensar un texto en una versión más corta, coherente e informativa mientras se preserva su significado esencial. Esta poderosa técnica agiliza los procesos comerciales en diversas industrias. En finanzas, por ejemplo, acelera la toma de decisiones al resumir informes extensos. En marketing, ayuda transformar los comentarios de los clientes en información procesable, lo que permite estrategias de campaña más efectivas. Podemos aprovechar los modelos de lenguaje para resumir un texto dado, pero debemos aprender cómo hacerlo de manera efectiva. primera vista, resumir texto consiste solo en proporcionar texto al modelo y pedirle que lo resuma. Aquí tenemos un texto que representa una reseña de un reloj inteligente sobre el diseño, la calidad y la comodidad del producto. Pedimos al modelo que lo resuma usando un prompt delimitado y sin otras instrucciones. Aunque el modelo resumirá el texto proporcionado, el prompt podría ser más efectivo ya que especifica detalles para guiar el comportamiento del modelo mientras resume. Podemos especificar los límites de la salida, la estructura de la salida y el enfoque del resumen para hacer el prompt más efectivo. El resultado sin más especificaciones se ve en la Figura 11.1.\nFigura 11.1: Resumen de un texto.\nImplementemos cada uno de estos. Podemos especificar los límites de la salida por el número de oraciones, palabras o caracteres. Aquí, para la misma reseña del reloj inteligente, modificamos el prompt para resumirlo en una oración, lo cual vemos reflejado en la salida en la Figura 11.2.\nFigura 11.2: Resumen de un texto especificando que sea en una sola frase.\nTambién podemos especificar la estructura de la salida mencionando explícitamente el formato deseado en el prompt. Por ejemplo, aquí pedimos al modelo que resuma la reseña del reloj inteligente en un máximo de tres puntos clave. Ahora la salida es un resumen de tres viñetas que refleja las cualidades del reloj como se puede ver en la Figura 11.3.\nFigura 11.3: Resumen de un texto especificando que sea 3 puntos clave.\nFinalmente, podemos pedir al modelo que se enfoque en aspectos específicos de la reseña del producto mientras resume. Aquí, por ejemplo, instruimos al modelo que resuma la reseña en tres oraciones, enfocándose en las características clave y la experiencia del usuario. Esto nos ayuda comprender rápidamente las fortalezas y debilidades del producto.\nFigura 11.4: Resumen de un texto especificando que sea 3 frases, características clave y experiencia de usuario.\nComo podemos ver en la Figura 11.4, la respuesta tiene precisamente 3 oraciones destacando los comentarios positivos del usuario y las características clave que disfrutaron del producto.Lo opuesto la resumido de texto es la expansión de texto, que tiene como objetivo generar texto basado en algunas ideas o puntos clave. La expansión de texto es altamente relevante para las empresas. Puede mejorar significativamente la eficiencia y productividad al agilizar la comunicación y reducir el tiempo dedicado tareas repetitivas como redactar correos electrónicos estandarizados o generar grandes volúmenes de texto para informes o documentación. Con LLMs, podemos expandir efectivamente el texto utilizando prompts bien elaborados. Un prompt típico de expansión de texto debe decirle al modelo que expanda un texto delimitado destacando los aspectos necesarios en los que centrarse mientras proporciona los requisitos de salida, incluyendo tono, longitud, estructura y audiencia. Ilustremos esta expansión con un ejemplo.\nFigura 11.5: Expansión de un texto dando indicaciones de cómo hacerlo.\nSupongamos que tenemos la descripción de la Figura 11.5 con puntos clave para un servicio relacionado con las redes sociales. Los puntos clave enumeran los servicios de la compañía, como creación de contenido y construcción de comunidad. Queremos crear un texto coherente para presentarlo efectivamente. Para hacerlo, pedimos al modelo que expanda la descripción del servicio para proporcionar una visión general de sus características y beneficios. Usando un prompt delimitado, y especificamos todos los requisitos de salida necesarios, incluyendo un límite de salida de dos oraciones como máximo y el tono profesional. El modelo expande la descripción del servicio en dos oraciones usando un tono profesional.","code":""},{"path":"aplicaciones-comerciales-de-la-ingeniería-de-prompts.html","id":"resumido-y-expansión-de-texto","chapter":"11 Aplicaciones Comerciales de la Ingeniería de Prompts","heading":"11.1 Resumido y Expansión de Texto","text":"Ahora que estamos cómodos con los principios y estrategias de la ingeniería de prompts, es hora de poner este conocimiento en práctica para diversas aplicaciones comerciales. Nos enfocaremos ahora en desarrollar prompts efectivos para el resumen y expansión de texto. El resumen de texto consiste en condensar un texto en una versión más corta, coherente e informativa mientras se preserva su significado esencial. Esta poderosa técnica agiliza los procesos comerciales en diversas industrias. En finanzas, por ejemplo, acelera la toma de decisiones al resumir informes extensos. En marketing, ayuda transformar los comentarios de los clientes en información procesable, lo que permite estrategias de campaña más efectivas. Podemos aprovechar los modelos de lenguaje para resumir un texto dado, pero debemos aprender cómo hacerlo de manera efectiva. primera vista, resumir texto consiste solo en proporcionar texto al modelo y pedirle que lo resuma. Aquí tenemos un texto que representa una reseña de un reloj inteligente sobre el diseño, la calidad y la comodidad del producto. Pedimos al modelo que lo resuma usando un prompt delimitado y sin otras instrucciones. Aunque el modelo resumirá el texto proporcionado, el prompt podría ser más efectivo ya que especifica detalles para guiar el comportamiento del modelo mientras resume. Podemos especificar los límites de la salida, la estructura de la salida y el enfoque del resumen para hacer el prompt más efectivo. El resultado sin más especificaciones se ve en la Figura 11.1.\nFigura 11.1: Resumen de un texto.\n","code":""},{"path":"aplicaciones-comerciales-de-la-ingeniería-de-prompts.html","id":"límites-de-salida-en-la-resumido-de-texto","chapter":"11 Aplicaciones Comerciales de la Ingeniería de Prompts","heading":"11.2 Límites de Salida en la Resumido de Texto","text":"Implementemos cada uno de estos. Podemos especificar los límites de la salida por el número de oraciones, palabras o caracteres. Aquí, para la misma reseña del reloj inteligente, modificamos el prompt para resumirlo en una oración, lo cual vemos reflejado en la salida en la Figura 11.2.\nFigura 11.2: Resumen de un texto especificando que sea en una sola frase.\n","code":""},{"path":"aplicaciones-comerciales-de-la-ingeniería-de-prompts.html","id":"estructura-de-salida-en-la-resumido-de-texto","chapter":"11 Aplicaciones Comerciales de la Ingeniería de Prompts","heading":"11.3 Estructura de Salida en la Resumido de Texto","text":"También podemos especificar la estructura de la salida mencionando explícitamente el formato deseado en el prompt. Por ejemplo, aquí pedimos al modelo que resuma la reseña del reloj inteligente en un máximo de tres puntos clave. Ahora la salida es un resumen de tres viñetas que refleja las cualidades del reloj como se puede ver en la Figura 11.3.\nFigura 11.3: Resumen de un texto especificando que sea 3 puntos clave.\n","code":""},{"path":"aplicaciones-comerciales-de-la-ingeniería-de-prompts.html","id":"enfoque-en-aspectos-específicos","chapter":"11 Aplicaciones Comerciales de la Ingeniería de Prompts","heading":"11.4 Enfoque en Aspectos Específicos","text":"Finalmente, podemos pedir al modelo que se enfoque en aspectos específicos de la reseña del producto mientras resume. Aquí, por ejemplo, instruimos al modelo que resuma la reseña en tres oraciones, enfocándose en las características clave y la experiencia del usuario. Esto nos ayuda comprender rápidamente las fortalezas y debilidades del producto.\nFigura 11.4: Resumen de un texto especificando que sea 3 frases, características clave y experiencia de usuario.\nComo podemos ver en la Figura 11.4, la respuesta tiene precisamente 3 oraciones destacando los comentarios positivos del usuario y las características clave que disfrutaron del producto.","code":""},{"path":"aplicaciones-comerciales-de-la-ingeniería-de-prompts.html","id":"expansión-de-texto","chapter":"11 Aplicaciones Comerciales de la Ingeniería de Prompts","heading":"11.5 Expansión de Texto","text":"Lo opuesto la resumido de texto es la expansión de texto, que tiene como objetivo generar texto basado en algunas ideas o puntos clave. La expansión de texto es altamente relevante para las empresas. Puede mejorar significativamente la eficiencia y productividad al agilizar la comunicación y reducir el tiempo dedicado tareas repetitivas como redactar correos electrónicos estandarizados o generar grandes volúmenes de texto para informes o documentación. Con LLMs, podemos expandir efectivamente el texto utilizando prompts bien elaborados. Un prompt típico de expansión de texto debe decirle al modelo que expanda un texto delimitado destacando los aspectos necesarios en los que centrarse mientras proporciona los requisitos de salida, incluyendo tono, longitud, estructura y audiencia. Ilustremos esta expansión con un ejemplo.\nFigura 11.5: Expansión de un texto dando indicaciones de cómo hacerlo.\nSupongamos que tenemos la descripción de la Figura 11.5 con puntos clave para un servicio relacionado con las redes sociales. Los puntos clave enumeran los servicios de la compañía, como creación de contenido y construcción de comunidad. Queremos crear un texto coherente para presentarlo efectivamente. Para hacerlo, pedimos al modelo que expanda la descripción del servicio para proporcionar una visión general de sus características y beneficios. Usando un prompt delimitado, y especificamos todos los requisitos de salida necesarios, incluyendo un límite de salida de dos oraciones como máximo y el tono profesional. El modelo expande la descripción del servicio en dos oraciones usando un tono profesional.","code":""},{"path":"transformación-de-texto.html","id":"transformación-de-texto","chapter":"12 Transformación de Texto","heading":"12 Transformación de Texto","text":"Ahora aprenderemos sobre aplicaciones de transformación de texto y cómo la ingeniería de prompts efectiva las facilita. Como su nombre lo indica, la transformación de texto implica hacer cambios lo largo de un texto dado para crear un nuevo texto mientras se mantiene la misma información. Tiene varias aplicaciones interesantes, incluyendo la traducción de idiomas, el ajuste de tono y la mejora de la escritura. Todas ellas se pueden hacer con LLMs utilizando prompts efectivos.La primera aplicación que cubriremos es la traducción de texto de un idioma otro. Al pedirle al LLM que traduzca un texto, debemos especificar los idiomas de entrada y salida en el prompt. Supongamos que tenemos la siguiente descripción de un producto para un scooter eléctrico escrita en inglés que describe su diseño. Pedimos al modelo que la traduzca del inglés al francés. Ver Figura 12.1.\nFigura 12.1: Traducción de un texto del inglés al francés.\nPero, ¿qué pasa si se conoce el idioma del texto de entrada? En este caso, podemos pedir al modelo con un prompt delimitado y nombrará el idioma. En este ejemplo, el texto está escrito en alemán y tal y como se ve en la Figura 12.2 detecta el idioma.\nFigura 12.2: Detección del lenguaje del texto.\nPodemos traducir texto de un idioma varios idiomas simultáneamente. Aquí pedimos al modelo que traduzca una reseña de producto en inglés al francés, español y alemán. El modelo genera una traducción en cada uno de los idiomas especificados. Las empresas pueden usar LLMS para proporcionar traducciones iniciales, pero deben verificar su corrección, particularmente si involucran clientes. Ver Figura 12.3.\nFigura 12.3: Resumen de un texto especificando que sea en una sola frase.\nOtra aplicación de la transformación de texto es el ajuste de tono, que nos permite reescribir texto con un tono diferente para satisfacer diversas necesidades comerciales. Por ejemplo, una empresa de marketing puede tener un mensaje promocional sobre sus ventas de verano escrito de manera informal. Podemos pedir al modelo que lo reformule en un tono formal y persuasivo para resonar mejor con la audiencia, especificando esto en el prompt delimitado. Aquí podemos observar cómo el texto se ha transformado en uno profesional que invita los clientes explorar las notables ventas de verano, destacando sus beneficios únicos. El tono ha cambiado y la estructura también es más profesional (Figura 12.4).\nFigura 12.4: Ajuste del tono de casual formal.\nPara adaptar el tono de un texto dado, podemos especificar la audiencia objetivo, una estrategia crucial en la comunicación efectiva. Por ejemplo, consideremos una descripción de producto escrita con jerga técnica, como detalles sobre microprocesadores y algoritmos complejos. Al instruir al modelo que lo reformule para una audiencia técnica, podemos hacerlo más accesible para los clientes que tienen un trasfondo técnico. En consecuencia, podemos observar en la Figura 12.5 cómo el estilo de escritura se adapta para incluir un vocabulario menos complejo.\nFigura 12.5: Ajuste del tono de técnico -técnico.\nOtros ejemplos comunes de transformación de texto incluyen mejoras gramaticales y de escritura. Si necesitamos que el modelo corrija errores de ortografía, gramática y puntuación sin modificar otros aspectos, debemos pedirle que revise nuestro texto mientras mantiene intacta la estructura. Para un texto que invita discutir una posible oportunidad de colaboración, el modelo corrigió los acentos sin alterar nada relacionado con el estilo o la estructura del texto tal y como se ve en la Figura 12.6.\nFigura 12.6: Corrección de los acentos de una frase.\nSin embargo, si queremos que el modelo mejore la claridad de nuestro texto modificando su estructura mientras mantiene el mismo significado, debemos pedirle que revise y reestructure el texto para mejorar la legibilidad, el flujo y la coherencia. En este caso, utilizando el mismo texto con los errores tipográficos, observamos cómo la estructura se vuelve más legible y bien escrita en la Figura 12.7.\nFigura 12.7: Pasar de un texto escrito en Whatsapp un formato legible, fluido y coherente.\nFinalmente, podemos realizar múltiples transformaciones la vez utilizando prompts de varios pasos. Supongamos que tenemos el siguiente texto para una reseña de producto escrita de manera informal con muchos errores.“XDIOS, ¡puedo creer lo awesome que es este producto! ¡Es best que existe! Ay que probarlo!”Pedimos al modelo que lo revise primero y luego lo reescriba en un tono profesional. El modelo pasa por las transformaciones solicitadas una por una, corrigiendo el texto en el paso uno, luego reescribiéndolo profesionalmente en el paso dos (Figura 12.8).\nFigura 12.8: Pasar de un texto escrito con muchos errores un formato legible y profesional.\n","code":""},{"path":"transformación-de-texto.html","id":"introducción-a-la-transformación-de-texto","chapter":"12 Transformación de Texto","heading":"12.1 Introducción a la Transformación de Texto","text":"Ahora aprenderemos sobre aplicaciones de transformación de texto y cómo la ingeniería de prompts efectiva las facilita. Como su nombre lo indica, la transformación de texto implica hacer cambios lo largo de un texto dado para crear un nuevo texto mientras se mantiene la misma información. Tiene varias aplicaciones interesantes, incluyendo la traducción de idiomas, el ajuste de tono y la mejora de la escritura. Todas ellas se pueden hacer con LLMs utilizando prompts efectivos.","code":""},{"path":"transformación-de-texto.html","id":"traducción-de-idiomas","chapter":"12 Transformación de Texto","heading":"12.2 Traducción de Idiomas","text":"La primera aplicación que cubriremos es la traducción de texto de un idioma otro. Al pedirle al LLM que traduzca un texto, debemos especificar los idiomas de entrada y salida en el prompt. Supongamos que tenemos la siguiente descripción de un producto para un scooter eléctrico escrita en inglés que describe su diseño. Pedimos al modelo que la traduzca del inglés al francés. Ver Figura 12.1.\nFigura 12.1: Traducción de un texto del inglés al francés.\nPero, ¿qué pasa si se conoce el idioma del texto de entrada? En este caso, podemos pedir al modelo con un prompt delimitado y nombrará el idioma. En este ejemplo, el texto está escrito en alemán y tal y como se ve en la Figura 12.2 detecta el idioma.\nFigura 12.2: Detección del lenguaje del texto.\nPodemos traducir texto de un idioma varios idiomas simultáneamente. Aquí pedimos al modelo que traduzca una reseña de producto en inglés al francés, español y alemán. El modelo genera una traducción en cada uno de los idiomas especificados. Las empresas pueden usar LLMS para proporcionar traducciones iniciales, pero deben verificar su corrección, particularmente si involucran clientes. Ver Figura 12.3.\nFigura 12.3: Resumen de un texto especificando que sea en una sola frase.\n","code":""},{"path":"transformación-de-texto.html","id":"ajuste-de-tono","chapter":"12 Transformación de Texto","heading":"12.3 Ajuste de Tono","text":"Otra aplicación de la transformación de texto es el ajuste de tono, que nos permite reescribir texto con un tono diferente para satisfacer diversas necesidades comerciales. Por ejemplo, una empresa de marketing puede tener un mensaje promocional sobre sus ventas de verano escrito de manera informal. Podemos pedir al modelo que lo reformule en un tono formal y persuasivo para resonar mejor con la audiencia, especificando esto en el prompt delimitado. Aquí podemos observar cómo el texto se ha transformado en uno profesional que invita los clientes explorar las notables ventas de verano, destacando sus beneficios únicos. El tono ha cambiado y la estructura también es más profesional (Figura 12.4).\nFigura 12.4: Ajuste del tono de casual formal.\nPara adaptar el tono de un texto dado, podemos especificar la audiencia objetivo, una estrategia crucial en la comunicación efectiva. Por ejemplo, consideremos una descripción de producto escrita con jerga técnica, como detalles sobre microprocesadores y algoritmos complejos. Al instruir al modelo que lo reformule para una audiencia técnica, podemos hacerlo más accesible para los clientes que tienen un trasfondo técnico. En consecuencia, podemos observar en la Figura 12.5 cómo el estilo de escritura se adapta para incluir un vocabulario menos complejo.\nFigura 12.5: Ajuste del tono de técnico -técnico.\n","code":""},{"path":"transformación-de-texto.html","id":"mejora-de-la-escritura","chapter":"12 Transformación de Texto","heading":"12.4 Mejora de la Escritura","text":"Otros ejemplos comunes de transformación de texto incluyen mejoras gramaticales y de escritura. Si necesitamos que el modelo corrija errores de ortografía, gramática y puntuación sin modificar otros aspectos, debemos pedirle que revise nuestro texto mientras mantiene intacta la estructura. Para un texto que invita discutir una posible oportunidad de colaboración, el modelo corrigió los acentos sin alterar nada relacionado con el estilo o la estructura del texto tal y como se ve en la Figura 12.6.\nFigura 12.6: Corrección de los acentos de una frase.\nSin embargo, si queremos que el modelo mejore la claridad de nuestro texto modificando su estructura mientras mantiene el mismo significado, debemos pedirle que revise y reestructure el texto para mejorar la legibilidad, el flujo y la coherencia. En este caso, utilizando el mismo texto con los errores tipográficos, observamos cómo la estructura se vuelve más legible y bien escrita en la Figura 12.7.\nFigura 12.7: Pasar de un texto escrito en Whatsapp un formato legible, fluido y coherente.\n","code":""},{"path":"transformación-de-texto.html","id":"transformaciones-múltiples","chapter":"12 Transformación de Texto","heading":"12.5 Transformaciones Múltiples","text":"Finalmente, podemos realizar múltiples transformaciones la vez utilizando prompts de varios pasos. Supongamos que tenemos el siguiente texto para una reseña de producto escrita de manera informal con muchos errores.“XDIOS, ¡puedo creer lo awesome que es este producto! ¡Es best que existe! Ay que probarlo!”Pedimos al modelo que lo revise primero y luego lo reescriba en un tono profesional. El modelo pasa por las transformaciones solicitadas una por una, corrigiendo el texto en el paso uno, luego reescribiéndolo profesionalmente en el paso dos (Figura 12.8).\nFigura 12.8: Pasar de un texto escrito con muchos errores un formato legible y profesional.\n","code":""},{"path":"análisis-de-texto.html","id":"análisis-de-texto","chapter":"13 Análisis de Texto","heading":"13 Análisis de Texto","text":"Es hora de analizar texto utilizando prompts efectivos. El análisis de texto es el proceso de examinar texto para extraer información relevante de él. Exploraremos técnicas de clasificación de texto y extracción de entidades, aplicándolas datos de muestra de clientes. Nótese que los ejemplos utilizados aquí son completamente ficticios, y las empresas siempre deben buscar asesoramiento legal para comprender cuándo y cómo usar los datos de los clientes en cumplimiento con las regulaciones y leyes de privacidad.Comencemos con la clasificación de texto, donde el objetivo es asignar una de varias categorías potenciales un texto específico. Una ilustración bien conocida de la clasificación de texto es el análisis de sentimientos, donde el objetivo es asignar un sentimiento como positivo, negativo o neutral un texto proporcionado. Para clasificar textos de manera efectiva, debemos especificar las categorías de clasificación en el prompt cuando se conocen, junto con los requisitos de salida que buscamos. Por ejemplo, al pedir al modelo que clasifique el sentimiento de una reseña de reloj inteligente, mencionamos explícitamente las opciones como positivo, negativo o neutral y pedimos una respuesta de una sola palabra. El modelo responde según nuestras especificaciones. Ver Figura 13.1.\nFigura 13.1: Clasificar un texto como positivo, negativo o neutral.\nCuando se especifican las categorías de clasificación, el modelo se basa en su conocimiento interno para realizar la clasificación. Supongamos que usamos el prompt del ejemplo anterior sin definir categorías. En ese caso, la salida será la misma ya que estamos buscando las salidas clásicas del análisis de sentimientos que el modelo ya conoce. Sin embargo, este enfoque es probable que produzca resultados esperados en ejemplos más complejos. Por esta razón, es mejor práctica proporcionar clases específicas cuando sea posible.veces los textos pueden encajar en múltiples clases. Por ejemplo, una reseña podría expresar múltiples emociones. Dado que las emociones pueden ser diversas, es posible que tengamos una lista completa predefinida. Podemos pedir al modelo que reconozca emociones sin proporcionarlas. Definir un número máximo de clases para listar para un texto dado es una mejor práctica en estas situaciones. Para la reseña del reloj inteligente, instruimos al modelo para que identifique un máximo de tres emociones separadas por comas. El modelo encuentra que el cliente estaba impresionado, cómodo y satisfecho (Figura 13.2).\nFigura 13.2: . Clasificar un texto con tres emociones.\nOtra forma de analizar texto es mediante la extracción de entidades, donde el objetivo es extraer entidades específicas de un texto dado, incluyendo nombres, lugares, organizaciones y fechas. Para extraer las entidades de manera efectiva, debemos especificar las entidades extraer y el formato de salida deseado. En este ejemplo, tenemos una descripción de producto para un teléfono móvil y pedimos al modelo que identifique el nombre del producto, el tamaño de la pantalla y la resolución de la cámara mientras formatea la respuesta como una lista desordenada.\nFigura 13.3: Ejemplo de extracción de entidades.\nVemos en la Figura 13.3 cómo el modelo extrae el nombre del producto, el tamaño de la pantalla y la resolución de la cámara, formateándolos como se solicitó.Cuando las entidades y su estructura son demasiado complejas para explicarlas al modelo, podemos usar un prompt de pocos disparos. Supongamos que tenemos dos ejemplos de tickets de soporte de 2 clientes que usan una aplicación de reserva de viajes y sus entidades extraídas. Observamos que las entidades poseen una estructura compleja donde las entidades principales como detalles del cliente y de la reserva son comunes para ambos tickets. Pero cada uno de ellos está representado además por subentidades que varían dependiendo de la información encontrada en el ticket correspondiente. Por ejemplo, la entidad uno tiene teléfono, pero la entidad dos . Supongamos que tenemos este nuevo ticket, ticket tres de un cliente llamado David y queremos extraer sus entidades de la misma manera que los dos tickets anteriores. Formulamos un prompt de pocos disparos que contiene los ejemplos de tickets, sus entidades extraídas y el nuevo ticket. El modelo en la Figura 13.4 extrae las entidades del ticket tres siguiendo una estructura similar los ejemplos proporcionados y capturando nuevas subentidades como el ID del cliente.\nFigura 13.4: Ejemplo de extracción de entidades con pocos disparos.\n","code":""},{"path":"análisis-de-texto.html","id":"introducción-al-análisis-de-texto","chapter":"13 Análisis de Texto","heading":"13.1 Introducción al Análisis de Texto","text":"Es hora de analizar texto utilizando prompts efectivos. El análisis de texto es el proceso de examinar texto para extraer información relevante de él. Exploraremos técnicas de clasificación de texto y extracción de entidades, aplicándolas datos de muestra de clientes. Nótese que los ejemplos utilizados aquí son completamente ficticios, y las empresas siempre deben buscar asesoramiento legal para comprender cuándo y cómo usar los datos de los clientes en cumplimiento con las regulaciones y leyes de privacidad.","code":""},{"path":"análisis-de-texto.html","id":"clasificación-de-texto","chapter":"13 Análisis de Texto","heading":"13.2 Clasificación de Texto","text":"Comencemos con la clasificación de texto, donde el objetivo es asignar una de varias categorías potenciales un texto específico. Una ilustración bien conocida de la clasificación de texto es el análisis de sentimientos, donde el objetivo es asignar un sentimiento como positivo, negativo o neutral un texto proporcionado. Para clasificar textos de manera efectiva, debemos especificar las categorías de clasificación en el prompt cuando se conocen, junto con los requisitos de salida que buscamos. Por ejemplo, al pedir al modelo que clasifique el sentimiento de una reseña de reloj inteligente, mencionamos explícitamente las opciones como positivo, negativo o neutral y pedimos una respuesta de una sola palabra. El modelo responde según nuestras especificaciones. Ver Figura 13.1.\nFigura 13.1: Clasificar un texto como positivo, negativo o neutral.\n","code":""},{"path":"análisis-de-texto.html","id":"análisis-de-sentimientos-sin-categorías-definidas","chapter":"13 Análisis de Texto","heading":"13.3 Análisis de Sentimientos sin Categorías Definidas","text":"Cuando se especifican las categorías de clasificación, el modelo se basa en su conocimiento interno para realizar la clasificación. Supongamos que usamos el prompt del ejemplo anterior sin definir categorías. En ese caso, la salida será la misma ya que estamos buscando las salidas clásicas del análisis de sentimientos que el modelo ya conoce. Sin embargo, este enfoque es probable que produzca resultados esperados en ejemplos más complejos. Por esta razón, es mejor práctica proporcionar clases específicas cuando sea posible.","code":""},{"path":"análisis-de-texto.html","id":"clasificación-de-textos-con-múltiples-clases","chapter":"13 Análisis de Texto","heading":"13.4 Clasificación de Textos con Múltiples Clases","text":"veces los textos pueden encajar en múltiples clases. Por ejemplo, una reseña podría expresar múltiples emociones. Dado que las emociones pueden ser diversas, es posible que tengamos una lista completa predefinida. Podemos pedir al modelo que reconozca emociones sin proporcionarlas. Definir un número máximo de clases para listar para un texto dado es una mejor práctica en estas situaciones. Para la reseña del reloj inteligente, instruimos al modelo para que identifique un máximo de tres emociones separadas por comas. El modelo encuentra que el cliente estaba impresionado, cómodo y satisfecho (Figura 13.2).\nFigura 13.2: . Clasificar un texto con tres emociones.\n","code":""},{"path":"análisis-de-texto.html","id":"extracción-de-entidades","chapter":"13 Análisis de Texto","heading":"13.5 Extracción de Entidades","text":"Otra forma de analizar texto es mediante la extracción de entidades, donde el objetivo es extraer entidades específicas de un texto dado, incluyendo nombres, lugares, organizaciones y fechas. Para extraer las entidades de manera efectiva, debemos especificar las entidades extraer y el formato de salida deseado. En este ejemplo, tenemos una descripción de producto para un teléfono móvil y pedimos al modelo que identifique el nombre del producto, el tamaño de la pantalla y la resolución de la cámara mientras formatea la respuesta como una lista desordenada.\nFigura 13.3: Ejemplo de extracción de entidades.\nVemos en la Figura 13.3 cómo el modelo extrae el nombre del producto, el tamaño de la pantalla y la resolución de la cámara, formateándolos como se solicitó.","code":""},{"path":"análisis-de-texto.html","id":"prompting-de-pocos-disparos-para-extracción-de-entidades","chapter":"13 Análisis de Texto","heading":"13.6 Prompting de Pocos Disparos para Extracción de Entidades","text":"Cuando las entidades y su estructura son demasiado complejas para explicarlas al modelo, podemos usar un prompt de pocos disparos. Supongamos que tenemos dos ejemplos de tickets de soporte de 2 clientes que usan una aplicación de reserva de viajes y sus entidades extraídas. Observamos que las entidades poseen una estructura compleja donde las entidades principales como detalles del cliente y de la reserva son comunes para ambos tickets. Pero cada uno de ellos está representado además por subentidades que varían dependiendo de la información encontrada en el ticket correspondiente. Por ejemplo, la entidad uno tiene teléfono, pero la entidad dos . Supongamos que tenemos este nuevo ticket, ticket tres de un cliente llamado David y queremos extraer sus entidades de la misma manera que los dos tickets anteriores. Formulamos un prompt de pocos disparos que contiene los ejemplos de tickets, sus entidades extraídas y el nuevo ticket. El modelo en la Figura 13.4 extrae las entidades del ticket tres siguiendo una estructura similar los ejemplos proporcionados y capturando nuevas subentidades como el ID del cliente.\nFigura 13.4: Ejemplo de extracción de entidades con pocos disparos.\n","code":""},{"path":"generación-y-explicación-de-código.html","id":"generación-y-explicación-de-código","chapter":"14 Generación y Explicación de Código","heading":"14 Generación y Explicación de Código","text":"Las últimas aplicaciones comerciales que cubriremos son la generación y explicación de código. Veamos cómo generar y explicar fragmentos de código con prompts efectivos. La generación de código crea automáticamente código que resuelve un problema dado. Es esencial en cualquier dominio que utilice soluciones de software. Sin embargo, se recomienda precaución al usar LLMS para generar código ya que una comprensión sólida del código generado es esencial para su uso práctico.Para generar código, debemos incluir en el prompt la descripción del problema, el lenguaje de programación objetivo y el formato del código generado, como script, función o clase. Por ejemplo, pedimos al modelo que escriba una función en Python que calcule el promedio de ventas por trimestre dado una lista de ventas trimestrales. El modelo genera una función llamada promedio_ventas_timestrales que recibe una lista de ventas trimestrales. Los elementos de la lista se suman y se dividen por la longitud de la lista para calcular su promedio. Finalmente, se devuelve el promedio de ventas (Figura 14.1).\nFigura 14.1: Generación de una función en Python dada la especificación por el usuario.\nEn lugar de descripciones explícitas de problemas, veces tenemos ejemplos de entrada y salida y queremos generar un programa que los mapee. Supongamos que tenemos los siguientes ejemplos de entrada y salida. Sabemos que las entradas son listas de ventas trimestrales de cuatro números cada una, pero necesitamos entender cómo se generan las salidas basadas en estas entradas. Pedimos al modelo que escriba un programa en Python que haga esto. Como podemos ver, el modelo primero establece la conexión entre las entradas y salidas al descubrir que una función de promedio mapeará cada entrada dada la salida correspondiente. Luego, proporciona la función correspondiente y muestra cómo se aplica los ejemplos (Figura 14.2).\nFigura 14.2: Generación de una función en Python dados unos ejemplos.\nEn lugar de pedir al modelo que genere código desde cero, podemos pedirle al modelo que modifique el código según algunos requisitos. Por ejemplo, este script en Python calcula las ventas totales partir de una lista de ventas trimestrales y imprime la salida. Pedimos al modelo que transforme el script en una función que podamos llamar para calcular las ventas totales. El modelo genera la función solicitada que calcula las ventas totales y el script modificado que la llama en una lista de ventas trimestrales en la Figura 14.3.\nFigura 14.3: Modificar el script delimitado {} una función para que se pueda llamar para calcular las ventas totales dadas las ventas trimestrales.\nPodríamos incluir múltiples modificaciones en un solo prompt. Usando el mismo script que teníamos, pediríamos al modelo que permita los usuarios ingresar parámetros de manera interactiva y verificar si son positivos, devolviendo un mensaje de error si lo son.Algunos fragmentos de código pueden volverse muy difíciles de interpretar, especialmente si son largos. Los LLMS pueden usarse para explicar un fragmento de código dado. Al pedir al modelo que explique un código específico, debemos dar orientación sobre nuestras expectativas para la longitud de esta explicación. Por ejemplo, podemos pedir al modelo que explique lo que hace el código en una oración y, en consecuencia, el modelo nos dará una explicación de alto nivel del propósito del código, que calcula el promedio de ventas por trimestre. También podemos pedir al modelo que explique el código en detalle. En este caso, usamos un prompt de cadena de pensamiento pidiendo al modelo que piense paso paso. Aplicamos este prompt para el mismo código que teníamos anteriormente. El modelo tomará un fragmento de código la vez y explicará su funcionalidad. Explica en la Figura 14.4 paso paso lo que ocurre en cada parte, comenzando con la definición de la función, pasando al cálculo y luego devolviendo el resultado. Finalmente, resume el propósito del código.\nFigura 14.4: Explicar el código delimitado entre {} dado en el Sistema de Prompt.\n","code":""},{"path":"generación-y-explicación-de-código.html","id":"introducción-a-la-generación-y-explicación-de-código","chapter":"14 Generación y Explicación de Código","heading":"14.1 Introducción a la Generación y Explicación de Código","text":"Las últimas aplicaciones comerciales que cubriremos son la generación y explicación de código. Veamos cómo generar y explicar fragmentos de código con prompts efectivos. La generación de código crea automáticamente código que resuelve un problema dado. Es esencial en cualquier dominio que utilice soluciones de software. Sin embargo, se recomienda precaución al usar LLMS para generar código ya que una comprensión sólida del código generado es esencial para su uso práctico.","code":""},{"path":"generación-y-explicación-de-código.html","id":"generación-de-código","chapter":"14 Generación y Explicación de Código","heading":"14.2 Generación de Código","text":"Para generar código, debemos incluir en el prompt la descripción del problema, el lenguaje de programación objetivo y el formato del código generado, como script, función o clase. Por ejemplo, pedimos al modelo que escriba una función en Python que calcule el promedio de ventas por trimestre dado una lista de ventas trimestrales. El modelo genera una función llamada promedio_ventas_timestrales que recibe una lista de ventas trimestrales. Los elementos de la lista se suman y se dividen por la longitud de la lista para calcular su promedio. Finalmente, se devuelve el promedio de ventas (Figura 14.1).\nFigura 14.1: Generación de una función en Python dada la especificación por el usuario.\n","code":""},{"path":"generación-y-explicación-de-código.html","id":"ejemplos-de-entrada-y-salida-para-generación-de-programas","chapter":"14 Generación y Explicación de Código","heading":"14.3 Ejemplos de Entrada y Salida para Generación de Programas","text":"En lugar de descripciones explícitas de problemas, veces tenemos ejemplos de entrada y salida y queremos generar un programa que los mapee. Supongamos que tenemos los siguientes ejemplos de entrada y salida. Sabemos que las entradas son listas de ventas trimestrales de cuatro números cada una, pero necesitamos entender cómo se generan las salidas basadas en estas entradas. Pedimos al modelo que escriba un programa en Python que haga esto. Como podemos ver, el modelo primero establece la conexión entre las entradas y salidas al descubrir que una función de promedio mapeará cada entrada dada la salida correspondiente. Luego, proporciona la función correspondiente y muestra cómo se aplica los ejemplos (Figura 14.2).\nFigura 14.2: Generación de una función en Python dados unos ejemplos.\n","code":""},{"path":"generación-y-explicación-de-código.html","id":"modificación-de-código-existente","chapter":"14 Generación y Explicación de Código","heading":"14.4 Modificación de Código Existente","text":"En lugar de pedir al modelo que genere código desde cero, podemos pedirle al modelo que modifique el código según algunos requisitos. Por ejemplo, este script en Python calcula las ventas totales partir de una lista de ventas trimestrales y imprime la salida. Pedimos al modelo que transforme el script en una función que podamos llamar para calcular las ventas totales. El modelo genera la función solicitada que calcula las ventas totales y el script modificado que la llama en una lista de ventas trimestrales en la Figura 14.3.\nFigura 14.3: Modificar el script delimitado {} una función para que se pueda llamar para calcular las ventas totales dadas las ventas trimestrales.\nPodríamos incluir múltiples modificaciones en un solo prompt. Usando el mismo script que teníamos, pediríamos al modelo que permita los usuarios ingresar parámetros de manera interactiva y verificar si son positivos, devolviendo un mensaje de error si lo son.","code":""},{"path":"generación-y-explicación-de-código.html","id":"explicación-de-código","chapter":"14 Generación y Explicación de Código","heading":"14.5 Explicación de Código","text":"Algunos fragmentos de código pueden volverse muy difíciles de interpretar, especialmente si son largos. Los LLMS pueden usarse para explicar un fragmento de código dado. Al pedir al modelo que explique un código específico, debemos dar orientación sobre nuestras expectativas para la longitud de esta explicación. Por ejemplo, podemos pedir al modelo que explique lo que hace el código en una oración y, en consecuencia, el modelo nos dará una explicación de alto nivel del propósito del código, que calcula el promedio de ventas por trimestre. También podemos pedir al modelo que explique el código en detalle. En este caso, usamos un prompt de cadena de pensamiento pidiendo al modelo que piense paso paso. Aplicamos este prompt para el mismo código que teníamos anteriormente. El modelo tomará un fragmento de código la vez y explicará su funcionalidad. Explica en la Figura 14.4 paso paso lo que ocurre en cada parte, comenzando con la definición de la función, pasando al cálculo y luego devolviendo el resultado. Finalmente, resume el propósito del código.\nFigura 14.4: Explicar el código delimitado entre {} dado en el Sistema de Prompt.\n","code":""},{"path":"desarrollo-de-chatbots.html","id":"desarrollo-de-chatbots","chapter":"15 Desarrollo de Chatbots","heading":"15 Desarrollo de Chatbots","text":"Exploremos la ingeniería de prompts para el desarrollo de chatbots. Hasta ahora, hemos visto cómo los prompts efectivos ayudan los usuarios optimizar su uso de un modelo de lenguaje. Pero ¿por qué la ingeniería de prompts es vital en el desarrollo de chatbots? Como desarrollador, predecir las preguntas de los usuarios es difícil al crear un chatbot. Podemos poseer datos valiosos sobre búsquedas en el sitio e investigaciones, pero el desafío radica en garantizar respuestas efectivas para cualquier consulta. Aquí es donde la ingeniería de prompts puede guiar el comportamiento del chatbot en la respuesta preguntas, asegurando tanto fiabilidad como efectividad.¿Cómo logramos esto usando la API de OpenAI? Recordemos que cada mensaje que enviamos tiene un rol designado (Usuario, Sistema, Asistente). Nos enfocaremos en los mensajes de sistema para construir un chatbot, ya que estos guían el comportamiento del modelo al responder los usuarios. Como recordatorio, el punto de acceso de finalización del chat es adecuado para el desarrollo de chatbots. través de este punto de acceso, enviamos una serie de mensajes al modelo en formato de lista, cada uno asignado un rol particular. En este ejemplo, enviamos un mensaje de sistema que dirige al chatbot actuar como un experto científico de datos, simplificando ideas complejas, seguido de un mensaje de usuario que busca una explicación de la ingeniería de prompts tal y como se ve en la Figura 15.1.\nFigura 15.1: Usar tanto el rol del usuario como el rol del sistema.\nDebemos incorporar directrices claras de respuesta para dirigir el comportamiento del modelo, incluyendo la audiencia objetivo, el tono esperado, la longitud de la salida y la estructura de la salida. necesitaremos definir todo, pero debemos ser específicos sobre lo que se adapte nuestro caso de uso. En el ejemplo de un chatbot financiero, podemos pedirle al modelo través del prompt del sistema que responda de manera precisa, formal y objetiva. Supongamos que el usuario pregunta la opinión del chatbot sobre las criptomonedas través de un prompt de usuario. Vemos cómo el chatbot responde con precisión, comenzando con la definición de criptomonedas y luego detallando sus ventajas y desventajas para mantenerse objetivo según nuestra solicitud. Y finalmente, proporciona un resumen. Ver Figura 15.2.\nFigura 15.2: Usar tanto el rol del usuario como el rol del sistema dándole más información de comportamiento.\nTambién queremos considerar la guía de comportamiento. Podemos usar prompts condicionales para decirle al modelo cómo responder las preguntas de los usuarios. Por ejemplo, podríamos querer que el chatbot financiero responda consultas relacionadas con las finanzas. Para hacerlo, le decimos al modelo en el prompt del sistema que responda preguntas financieras lo mejor posible y para otras preguntas, la respuesta debe ser “Lo siento, solo sé sobre finanzas”.\nFigura 15.3: Usar tanto el rol del usuario como el rol del sistema dándole más información de comportamiento en formato condicional.\nEn consecuencia, si un usuario pregunta sobre el clima, el chatbot aclarará que su único dominio es finanzas tal y como se ve en la Figura 15.3.","code":""},{"path":"desarrollo-de-chatbots.html","id":"importancia-de-la-ingeniería-de-prompts-en-chatbots","chapter":"15 Desarrollo de Chatbots","heading":"15.1 Importancia de la Ingeniería de Prompts en Chatbots","text":"Exploremos la ingeniería de prompts para el desarrollo de chatbots. Hasta ahora, hemos visto cómo los prompts efectivos ayudan los usuarios optimizar su uso de un modelo de lenguaje. Pero ¿por qué la ingeniería de prompts es vital en el desarrollo de chatbots? Como desarrollador, predecir las preguntas de los usuarios es difícil al crear un chatbot. Podemos poseer datos valiosos sobre búsquedas en el sitio e investigaciones, pero el desafío radica en garantizar respuestas efectivas para cualquier consulta. Aquí es donde la ingeniería de prompts puede guiar el comportamiento del chatbot en la respuesta preguntas, asegurando tanto fiabilidad como efectividad.","code":""},{"path":"desarrollo-de-chatbots.html","id":"uso-de-la-api-de-openai-en-chatbots","chapter":"15 Desarrollo de Chatbots","heading":"15.2 Uso de la API de OpenAI en Chatbots","text":"¿Cómo logramos esto usando la API de OpenAI? Recordemos que cada mensaje que enviamos tiene un rol designado (Usuario, Sistema, Asistente). Nos enfocaremos en los mensajes de sistema para construir un chatbot, ya que estos guían el comportamiento del modelo al responder los usuarios. Como recordatorio, el punto de acceso de finalización del chat es adecuado para el desarrollo de chatbots. través de este punto de acceso, enviamos una serie de mensajes al modelo en formato de lista, cada uno asignado un rol particular. En este ejemplo, enviamos un mensaje de sistema que dirige al chatbot actuar como un experto científico de datos, simplificando ideas complejas, seguido de un mensaje de usuario que busca una explicación de la ingeniería de prompts tal y como se ve en la Figura 15.1.\nFigura 15.1: Usar tanto el rol del usuario como el rol del sistema.\n","code":""},{"path":"desarrollo-de-chatbots.html","id":"directrices-de-respuesta-para-chatbots","chapter":"15 Desarrollo de Chatbots","heading":"15.3 Directrices de Respuesta para Chatbots","text":"Debemos incorporar directrices claras de respuesta para dirigir el comportamiento del modelo, incluyendo la audiencia objetivo, el tono esperado, la longitud de la salida y la estructura de la salida. necesitaremos definir todo, pero debemos ser específicos sobre lo que se adapte nuestro caso de uso. En el ejemplo de un chatbot financiero, podemos pedirle al modelo través del prompt del sistema que responda de manera precisa, formal y objetiva. Supongamos que el usuario pregunta la opinión del chatbot sobre las criptomonedas través de un prompt de usuario. Vemos cómo el chatbot responde con precisión, comenzando con la definición de criptomonedas y luego detallando sus ventajas y desventajas para mantenerse objetivo según nuestra solicitud. Y finalmente, proporciona un resumen. Ver Figura 15.2.\nFigura 15.2: Usar tanto el rol del usuario como el rol del sistema dándole más información de comportamiento.\nTambién queremos considerar la guía de comportamiento. Podemos usar prompts condicionales para decirle al modelo cómo responder las preguntas de los usuarios. Por ejemplo, podríamos querer que el chatbot financiero responda consultas relacionadas con las finanzas. Para hacerlo, le decimos al modelo en el prompt del sistema que responda preguntas financieras lo mejor posible y para otras preguntas, la respuesta debe ser “Lo siento, solo sé sobre finanzas”.\nFigura 15.3: Usar tanto el rol del usuario como el rol del sistema dándole más información de comportamiento en formato condicional.\nEn consecuencia, si un usuario pregunta sobre el clima, el chatbot aclarará que su único dominio es finanzas tal y como se ve en la Figura 15.3.","code":""},{"path":"juego-de-roles-en-chatbots.html","id":"juego-de-roles-en-chatbots","chapter":"16 Juego de Roles en Chatbots","heading":"16 Juego de Roles en Chatbots","text":"Un aspecto importante que discutir al hablar del desarrollo de chatbots son los prompts de juego de roles. Veamos qué son estos. Los prompts de juego de roles indican al chatbot que juegue un papel específico al responder las preguntas de los usuarios. Imagina el chatbot como un actor en una obra; un prompt de juego de roles es como darle al actor un personaje para interpretar. Así como el actor se sumerge en la mentalidad, personalidad y contexto del personaje que está interpretando, el chatbot adopta un enfoque similar ajustando su tono, vocabulario y comportamiento para cumplir con los requisitos del rol. Esto significa que el chatbot adapta su lenguaje y contenido para ajustarse la persona en lugar de proporcionar respuestas genéricas. El juego de roles garantiza interacciones más efectivas, especialmente en chatbots específicos de dominio como salud, fitness, educación y finanzas. Nótese que el chatbot aprende interpretar estos roles basándose en sus datos de entrenamiento.Primero pasaremos por un ejemplo simbólico para comprender mejor los prompts de juego de roles y luego aprenderemos cómo implementarlos. Imagina que estamos desarrollando un chatbot para una empresa que ofrece productos técnicos complejos. Un cliente pregunta sobre las especificaciones técnicas de un producto determinado. Hemos definido 3 roles para el chatbot: agente de soporte al cliente, gerente de producto e ingeniero de ventas. ¿Cómo respondería cada uno de estos roles? El agente de soporte al cliente proporciona una guía general, dirige los clientes al sitio web para obtener más detalles y ofrece asistencia. El gerente de producto destaca los beneficios estratégicos, enfocándose en cómo el producto se alinea con los objetivos y necesidades profesionales. El ingeniero de ventas profundiza en los detalles técnicos, discutiendo detalles del procesador, características y seguridad. De este ejemplo podemos ver cómo el rol de un chatbot puede afectar cómo responde.Ahora que entendemos qué son los prompts de juego de roles, es hora de aprender cómo implementarlos. Debemos decirle al modelo que actúe como un rol específico, sin importar cuál sea ese rol. Por ejemplo, podemos pedirle al modelo que actúe como un analista financiero experto y luego pedirle que ofrezca ideas sobre la planificación de la jubilación para personas que se acercan la edad de jubilación. Vemos cómo la respuesta se moldea como si un verdadero experto en análisis financiero la proporcionara, destacando varias consideraciones tener en cuenta al planificar su jubilación. Los prompts de juego de roles implican más que solo asignar un rol. Encierran requisitos específicos dentro de ese rol. Por ejemplo, aunque dos periodistas pueden compartir puntos en común, son diferentes. Es por eso que, además del rol mismo, es esencial incorporar rasgos como personalidad y experiencia. Por ejemplo, podemos instruir al chatbot para que encarne la persona de un periodista de tecnología especializado en una investigación y análisis exhaustivos de la industria tecnológica. Luego podemos preguntar sobre el impacto de la IA en el mercado laboral (Figura 16.1).\nFigura 16.1: Ejemplo del uso de juego de roles.\nAquí podemos ver cómo el modelo responde como un periodista adecuado, ya que formateó la respuesta como un artículo. Además, proporcionó un análisis detallado del tema.Como nota final, debemos tener en cuenta que el juego de roles elimina la necesidad de especificar otros requisitos como las pautas de comportamiento o de respuesta. Por ejemplo, en el escenario del chatbot periodista, si queríamos que manejara exclusivamente preguntas relacionadas con la tecnología. Modificamos el prompt para probar esta condición y dejar que muestre un mensaje apropiado si se cumple. Si un usuario pregunta sobre un tema como la literatura catalana, el chatbot aclarará su especialización en tecnología. (Figura 16.2).\nFigura 16.2: Ejemplo del uso de juego de roles añadiendo más requerimientos.\n","code":""},{"path":"juego-de-roles-en-chatbots.html","id":"introducción-al-juego-de-roles-en-chatbots","chapter":"16 Juego de Roles en Chatbots","heading":"16.1 Introducción al Juego de Roles en Chatbots","text":"Un aspecto importante que discutir al hablar del desarrollo de chatbots son los prompts de juego de roles. Veamos qué son estos. Los prompts de juego de roles indican al chatbot que juegue un papel específico al responder las preguntas de los usuarios. Imagina el chatbot como un actor en una obra; un prompt de juego de roles es como darle al actor un personaje para interpretar. Así como el actor se sumerge en la mentalidad, personalidad y contexto del personaje que está interpretando, el chatbot adopta un enfoque similar ajustando su tono, vocabulario y comportamiento para cumplir con los requisitos del rol. Esto significa que el chatbot adapta su lenguaje y contenido para ajustarse la persona en lugar de proporcionar respuestas genéricas. El juego de roles garantiza interacciones más efectivas, especialmente en chatbots específicos de dominio como salud, fitness, educación y finanzas. Nótese que el chatbot aprende interpretar estos roles basándose en sus datos de entrenamiento.","code":""},{"path":"juego-de-roles-en-chatbots.html","id":"ejemplo-simbólico-de-juego-de-roles","chapter":"16 Juego de Roles en Chatbots","heading":"16.2 Ejemplo Simbólico de Juego de Roles","text":"Primero pasaremos por un ejemplo simbólico para comprender mejor los prompts de juego de roles y luego aprenderemos cómo implementarlos. Imagina que estamos desarrollando un chatbot para una empresa que ofrece productos técnicos complejos. Un cliente pregunta sobre las especificaciones técnicas de un producto determinado. Hemos definido 3 roles para el chatbot: agente de soporte al cliente, gerente de producto e ingeniero de ventas. ¿Cómo respondería cada uno de estos roles? El agente de soporte al cliente proporciona una guía general, dirige los clientes al sitio web para obtener más detalles y ofrece asistencia. El gerente de producto destaca los beneficios estratégicos, enfocándose en cómo el producto se alinea con los objetivos y necesidades profesionales. El ingeniero de ventas profundiza en los detalles técnicos, discutiendo detalles del procesador, características y seguridad. De este ejemplo podemos ver cómo el rol de un chatbot puede afectar cómo responde.","code":""},{"path":"juego-de-roles-en-chatbots.html","id":"implementación-del-juego-de-roles","chapter":"16 Juego de Roles en Chatbots","heading":"16.3 Implementación del Juego de Roles","text":"Ahora que entendemos qué son los prompts de juego de roles, es hora de aprender cómo implementarlos. Debemos decirle al modelo que actúe como un rol específico, sin importar cuál sea ese rol. Por ejemplo, podemos pedirle al modelo que actúe como un analista financiero experto y luego pedirle que ofrezca ideas sobre la planificación de la jubilación para personas que se acercan la edad de jubilación. Vemos cómo la respuesta se moldea como si un verdadero experto en análisis financiero la proporcionara, destacando varias consideraciones tener en cuenta al planificar su jubilación. Los prompts de juego de roles implican más que solo asignar un rol. Encierran requisitos específicos dentro de ese rol. Por ejemplo, aunque dos periodistas pueden compartir puntos en común, son diferentes. Es por eso que, además del rol mismo, es esencial incorporar rasgos como personalidad y experiencia. Por ejemplo, podemos instruir al chatbot para que encarne la persona de un periodista de tecnología especializado en una investigación y análisis exhaustivos de la industria tecnológica. Luego podemos preguntar sobre el impacto de la IA en el mercado laboral (Figura 16.1).\nFigura 16.1: Ejemplo del uso de juego de roles.\nAquí podemos ver cómo el modelo responde como un periodista adecuado, ya que formateó la respuesta como un artículo. Además, proporcionó un análisis detallado del tema.","code":""},{"path":"juego-de-roles-en-chatbots.html","id":"combinación-de-juego-de-roles-y-directrices","chapter":"16 Juego de Roles en Chatbots","heading":"16.4 Combinación de Juego de Roles y Directrices","text":"Como nota final, debemos tener en cuenta que el juego de roles elimina la necesidad de especificar otros requisitos como las pautas de comportamiento o de respuesta. Por ejemplo, en el escenario del chatbot periodista, si queríamos que manejara exclusivamente preguntas relacionadas con la tecnología. Modificamos el prompt para probar esta condición y dejar que muestre un mensaje apropiado si se cumple. Si un usuario pregunta sobre un tema como la literatura catalana, el chatbot aclarará su especialización en tecnología. (Figura 16.2).\nFigura 16.2: Ejemplo del uso de juego de roles añadiendo más requerimientos.\n","code":""},{"path":"incorporación-de-contexto-externo-en-chatbots.html","id":"incorporación-de-contexto-externo-en-chatbots","chapter":"17 Incorporación de Contexto Externo en Chatbots","heading":"17 Incorporación de Contexto Externo en Chatbots","text":"Una consideración clave al crear un chatbot es incorporar algún contexto externo. Veamos por qué es importante y cómo podemos lograrlo. Usamos un modelo de lenguaje preentrenado al construir un chatbot usando la API de OpenAI. Tales modelos solo reconocen información específica en la que han sido entrenados. Sin embargo, podríamos querer que nuestro chatbot sepa más que eso. Debemos proporcionarle algún contexto sobre la información faltante para asegurar que responda con precisión y efectividad las preguntas de los usuarios.Pero ¿por qué los LLM parecen tener dificultades para tener alguna información? Hay dos razones principales. Primero, los modelos de lenguaje han sido entrenados en grandes cantidades de datos de la web. Por lo tanto, cuando les preguntamos sobre un concepto que ocurrió después de que el modelo fue entrenado, o después de lo que llamamos el corte de conocimiento, tendrán dificultades para responder o inventarán una respuesta. Por ejemplo, si preguntamos un modelo de lenguaje lanzado en 2021 sobre las tendencias financieras prominentes de 2023, su respuesta podría ser: “Lo siento, pero hasta mi última actualización de conocimiento en 2021, tengo información sobre las tendencias financieras en 2023”. Puede que hayamos encontrado mensajes similares de ChatGPT al buscar información actualizada. Segundo, la información que estamos preguntando al modelo podría estar disponible públicamente, lo que significa que está fuera del alcance de su entrenamiento. En ese caso, se podría esperar que el modelo sepa la respuesta.Supongamos que pedimos al chatbot través de un prompt del sistema que actúe como un compañero de estudio. Luego preguntamos través de un prompt de usuario sobre el nombre del instructor favorito. Esta es una pregunta personal que el modelo sabría. Necesitamos proporcionar información adicional al modelo como contexto para que el chatbot la use al responder las preguntas de los usuarios. El contexto puede darse como una muestra de conversaciones previas o través del prompt inicial del sistema. Podemos proporcionar conversaciones de muestra que guíen al modelo sobre cómo debe responder preguntas específicas. Por ejemplo, comenzamos diciendo al modelo través de un mensaje del sistema que es un chatbot de servicio al cliente. Le proporcionamos un prompt de ejemplo donde el usuario pregunta sobre los servicios que ofrece la empresa. Luego proporcionamos una respuesta del asistente que incluye los servicios proporcionados. Finalmente, el modelo reconocerá esta información del contexto cuando preguntemos cuántos servicios se ofrecen. (Figura 17.1).\nFigura 17.1: Ejemplo de incorporación de contexto externo.\nUna desventaja de este método es que podría requerir muchas preguntas y respuestas de muestra. Una forma más efectiva de hacer esto es proporcionar el contexto dentro del prompt del sistema. Supongamos que una empresa llamada ABC Tech Solutions quiere que el modelo conozca sus servicios. La empresa debe definirlos inicialmente dentro de la variable de cadena. Luego, el prompt del sistema incluirá los servicios y las partes clásicas del prompt del sistema que hemos aprendido, incluyendo el propósito del chatbot y las pautas de comportamiento. Cuando un usuario pregunta sobre el número de servicios que ofrece la empresa, el modelo responderá con los tres servicios del prompt del sistema: desarrollo de aplicaciones web, desarrollo de aplicaciones móviles, y soluciones de software personalizadas. Una cosa tener en cuenta es que estos métodos funcionarán bien para contextos relativamente pequeños porque cualquier LLM tendrá algunas limitaciones en la cantidad de contexto que puede manejar. Cuando se necesita una gran cantidad de contexto, deben aplicarse técnicas más sofisticadas que están fuera del alcance de este curso. (Figura 17.2).\nFigura 17.2: Ejemplo de incorporación de contexto externo de muestra.\n","code":""},{"path":"incorporación-de-contexto-externo-en-chatbots.html","id":"introducción-a-la-incorporación-de-contexto-externo","chapter":"17 Incorporación de Contexto Externo en Chatbots","heading":"17.1 Introducción a la Incorporación de Contexto Externo","text":"Una consideración clave al crear un chatbot es incorporar algún contexto externo. Veamos por qué es importante y cómo podemos lograrlo. Usamos un modelo de lenguaje preentrenado al construir un chatbot usando la API de OpenAI. Tales modelos solo reconocen información específica en la que han sido entrenados. Sin embargo, podríamos querer que nuestro chatbot sepa más que eso. Debemos proporcionarle algún contexto sobre la información faltante para asegurar que responda con precisión y efectividad las preguntas de los usuarios.","code":""},{"path":"incorporación-de-contexto-externo-en-chatbots.html","id":"limitaciones-de-conocimiento-de-los-llms","chapter":"17 Incorporación de Contexto Externo en Chatbots","heading":"17.2 Limitaciones de Conocimiento de los LLMs","text":"Pero ¿por qué los LLM parecen tener dificultades para tener alguna información? Hay dos razones principales. Primero, los modelos de lenguaje han sido entrenados en grandes cantidades de datos de la web. Por lo tanto, cuando les preguntamos sobre un concepto que ocurrió después de que el modelo fue entrenado, o después de lo que llamamos el corte de conocimiento, tendrán dificultades para responder o inventarán una respuesta. Por ejemplo, si preguntamos un modelo de lenguaje lanzado en 2021 sobre las tendencias financieras prominentes de 2023, su respuesta podría ser: “Lo siento, pero hasta mi última actualización de conocimiento en 2021, tengo información sobre las tendencias financieras en 2023”. Puede que hayamos encontrado mensajes similares de ChatGPT al buscar información actualizada. Segundo, la información que estamos preguntando al modelo podría estar disponible públicamente, lo que significa que está fuera del alcance de su entrenamiento. En ese caso, se podría esperar que el modelo sepa la respuesta.","code":""},{"path":"incorporación-de-contexto-externo-en-chatbots.html","id":"provisión-de-contexto-externo","chapter":"17 Incorporación de Contexto Externo en Chatbots","heading":"17.3 Provisión de Contexto Externo","text":"Supongamos que pedimos al chatbot través de un prompt del sistema que actúe como un compañero de estudio. Luego preguntamos través de un prompt de usuario sobre el nombre del instructor favorito. Esta es una pregunta personal que el modelo sabría. Necesitamos proporcionar información adicional al modelo como contexto para que el chatbot la use al responder las preguntas de los usuarios. El contexto puede darse como una muestra de conversaciones previas o través del prompt inicial del sistema. Podemos proporcionar conversaciones de muestra que guíen al modelo sobre cómo debe responder preguntas específicas. Por ejemplo, comenzamos diciendo al modelo través de un mensaje del sistema que es un chatbot de servicio al cliente. Le proporcionamos un prompt de ejemplo donde el usuario pregunta sobre los servicios que ofrece la empresa. Luego proporcionamos una respuesta del asistente que incluye los servicios proporcionados. Finalmente, el modelo reconocerá esta información del contexto cuando preguntemos cuántos servicios se ofrecen. (Figura 17.1).\nFigura 17.1: Ejemplo de incorporación de contexto externo.\n","code":""},{"path":"incorporación-de-contexto-externo-en-chatbots.html","id":"limitaciones-del-contexto-de-muestra","chapter":"17 Incorporación de Contexto Externo en Chatbots","heading":"17.4 Limitaciones del Contexto de Muestra","text":"Una desventaja de este método es que podría requerir muchas preguntas y respuestas de muestra. Una forma más efectiva de hacer esto es proporcionar el contexto dentro del prompt del sistema. Supongamos que una empresa llamada ABC Tech Solutions quiere que el modelo conozca sus servicios. La empresa debe definirlos inicialmente dentro de la variable de cadena. Luego, el prompt del sistema incluirá los servicios y las partes clásicas del prompt del sistema que hemos aprendido, incluyendo el propósito del chatbot y las pautas de comportamiento. Cuando un usuario pregunta sobre el número de servicios que ofrece la empresa, el modelo responderá con los tres servicios del prompt del sistema: desarrollo de aplicaciones web, desarrollo de aplicaciones móviles, y soluciones de software personalizadas. Una cosa tener en cuenta es que estos métodos funcionarán bien para contextos relativamente pequeños porque cualquier LLM tendrá algunas limitaciones en la cantidad de contexto que puede manejar. Cuando se necesita una gran cantidad de contexto, deben aplicarse técnicas más sofisticadas que están fuera del alcance de este curso. (Figura 17.2).\nFigura 17.2: Ejemplo de incorporación de contexto externo de muestra.\n","code":""},{"path":"conclusión-del-curso.html","id":"conclusión-del-curso","chapter":"18 Conclusión del Curso","heading":"18 Conclusión del Curso","text":"lo largo de este viaje de aprendizaje, dominado las complejidades de la ingeniería de prompts para obtener resultados óptimos con los modelos de lenguaje y todo esto utilizando la aplicación de Shiny (https://testestestest.shinyapps.io/TFGUOC/).Antes de empezar el curso hemos revisado los aspectos éticos de la inteligencia artificial. En la primera parte del curso hemos visto el funcionamiento de esta aplicación. continuación ya se aborda el curso de Ingeniería de Prompts con ChatGPT. En el BLOQUE 1, sentaste las bases al entender los principios y mejores prácticas de la ingeniería de prompts, incluyendo prompts delimitados y condicionales y salidas estructuradas. contincuación, y en el BLOQUE 2, nivelaste tus habilidades con técnicas avanzadas como pocos disparos, varios pasos, cadena de pensamiento, auto coherencia y prompting iterativo para abordar tareas complejas. Luego y en el BLOQUE 3 aplicaste todas estas técnicas, donde te aventuraste en aplicaciones comerciales del mundo real confiando en técnicas como la resumido, la expansión y más. En la última parte (BLOQUE 4), te convertiste en un virtuoso del chatbot y dominaste el diseño de prompts de sistema través de técnicas como el juego de roles y la adición de contexto externo.Vale la pena recordar que, aunque la ingeniería de prompts mejora el rendimiento y produce mejores resultados de un modelo de lenguaje, tales modelos tienen limitaciones al igual que cualquier otro sistema. Y aunque la ingeniería de prompts precisa siempre garantiza resultados deseados. Por esta razón, siempre debes revisar las respuestas meticulosamente para verificar su exactitud y posibles sesgos, y evitar usarlas sin reflexión para asegurar el rendimiento más óptimo. Mantente curioso, mantente creativo y sigue empujando los límites del prompt.","code":""},{"path":"conclusión-del-curso.html","id":"resumen-del-curso","chapter":"18 Conclusión del Curso","heading":"18.1 Resumen del Curso","text":"lo largo de este viaje de aprendizaje, dominado las complejidades de la ingeniería de prompts para obtener resultados óptimos con los modelos de lenguaje y todo esto utilizando la aplicación de Shiny (https://testestestest.shinyapps.io/TFGUOC/).Antes de empezar el curso hemos revisado los aspectos éticos de la inteligencia artificial. En la primera parte del curso hemos visto el funcionamiento de esta aplicación. continuación ya se aborda el curso de Ingeniería de Prompts con ChatGPT. En el BLOQUE 1, sentaste las bases al entender los principios y mejores prácticas de la ingeniería de prompts, incluyendo prompts delimitados y condicionales y salidas estructuradas. contincuación, y en el BLOQUE 2, nivelaste tus habilidades con técnicas avanzadas como pocos disparos, varios pasos, cadena de pensamiento, auto coherencia y prompting iterativo para abordar tareas complejas. Luego y en el BLOQUE 3 aplicaste todas estas técnicas, donde te aventuraste en aplicaciones comerciales del mundo real confiando en técnicas como la resumido, la expansión y más. En la última parte (BLOQUE 4), te convertiste en un virtuoso del chatbot y dominaste el diseño de prompts de sistema través de técnicas como el juego de roles y la adición de contexto externo.","code":""},{"path":"conclusión-del-curso.html","id":"limitaciones-y-recomendaciones-finales","chapter":"18 Conclusión del Curso","heading":"18.2 Limitaciones y Recomendaciones Finales","text":"Vale la pena recordar que, aunque la ingeniería de prompts mejora el rendimiento y produce mejores resultados de un modelo de lenguaje, tales modelos tienen limitaciones al igual que cualquier otro sistema. Y aunque la ingeniería de prompts precisa siempre garantiza resultados deseados. Por esta razón, siempre debes revisar las respuestas meticulosamente para verificar su exactitud y posibles sesgos, y evitar usarlas sin reflexión para asegurar el rendimiento más óptimo. Mantente curioso, mantente creativo y sigue empujando los límites del prompt.","code":""},{"path":"referencias.html","id":"referencias","chapter":"19 Referencias","heading":"19 Referencias","text":"Crawford, J., Cowling, M., & Allen, K. (2023). Leadership needed ethical ChatGPT: Character, assessment, learning using artificial intelligence (AI). Journal University Teaching & Learning Practice, 20(3). https://doi.org/10.53761/1.20.3.02Crawford, J., Cowling, M., & Allen, K. (2023). Leadership needed ethical ChatGPT: Character, assessment, learning using artificial intelligence (AI). Journal University Teaching & Learning Practice, 20(3). https://doi.org/10.53761/1.20.3.02DLAI - ChatGPT Prompt Engineering Developers. (2024). Retrieved May 14, 2024, https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/4/summarizingDLAI - ChatGPT Prompt Engineering Developers. (2024). Retrieved May 14, 2024, https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/4/summarizingFranklin, J. (2024). AI Ethics - DataCamp Learn. https://app.datacamp.com/learn/courses/ai-ethicsFranklin, J. (2024). AI Ethics - DataCamp Learn. https://app.datacamp.com/learn/courses/ai-ethicsRahimi, F., & Abadi, . T. (2023). ChatGPT Publication Ethics. Archives Medical Research, 54(3), 272-274. https://doi.org/10.1016/j.arcmed.2023.03.004Rahimi, F., & Abadi, . T. (2023). ChatGPT Publication Ethics. Archives Medical Research, 54(3), 272-274. https://doi.org/10.1016/j.arcmed.2023.03.004Tawfeeq, M., Awqati, . J., & Jasim, Y. . (2023). Ethical Implications ChatGPT AI Chatbot: Review. Journal Modern Computing Engineering Research, 2023, 49-57.Tawfeeq, M., Awqati, . J., & Jasim, Y. . (2023). Ethical Implications ChatGPT AI Chatbot: Review. Journal Modern Computing Engineering Research, 2023, 49-57.Trad, F. (2024). ChatGPT Prompt Engineering Developers - DataCamp Learn. https://app.datacamp.com/learn/courses/chatgpt-prompt-engineering--developersTrad, F. (2024). ChatGPT Prompt Engineering Developers - DataCamp Learn. https://app.datacamp.com/learn/courses/chatgpt-prompt-engineering--developers","code":""}]
